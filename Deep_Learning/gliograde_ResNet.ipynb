{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8ec5a4-ddab-499b-978d-308bd1f9d93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working from: /home/jovyan/shared/data/PDGM/UCSF-PDGM-v5/UCSF-PDGM-v5\n",
      "Extracting subject IDs...\n",
      "==================================================\n",
      "Found 501 subjects:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchio as tio\n",
    "\n",
    "# Set the base directory\n",
    "base_path = '/home/jovyan/shared/data/PDGM/UCSF-PDGM-v5/UCSF-PDGM-v5'\n",
    "os.chdir(base_path)\n",
    "\n",
    "print(f\"Working from: {os.getcwd()}\")\n",
    "print(\"Extracting subject IDs...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get all subject directories and extract IDs\n",
    "subject_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and 'UCSF-PDGM-' in d and '_nifti' in d]\n",
    "\n",
    "# Extract clean subject IDs\n",
    "subject_ids = []\n",
    "for subject_dir in subject_dirs:\n",
    "    # Remove '_nifti' suffix to get clean ID\n",
    "    subject_id = subject_dir.replace('_nifti', '')\n",
    "    subject_ids.append(subject_id)\n",
    "\n",
    "# Sort the subject IDs\n",
    "subject_ids.sort()\n",
    "\n",
    "print(f\"Found {len(subject_ids)} subjects:\")\n",
    "#print(\"=\" * 30)\n",
    "#for i, subject_id in enumerate(subject_ids, 1):\n",
    "#    print(f\"{i:2d}. {subject_id}\")\n",
    "\n",
    "#print(f\"\\nTotal subjects: {len(subject_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "300692b8-9159-4dab-8f09-9743f257350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 501 DTI FA images\n",
      "Subject IDs with loaded images: ['UCSF-PDGM-0004', 'UCSF-PDGM-0005', 'UCSF-PDGM-0007', 'UCSF-PDGM-0008', 'UCSF-PDGM-0009', 'UCSF-PDGM-0010', 'UCSF-PDGM-0011', 'UCSF-PDGM-0012', 'UCSF-PDGM-0013', 'UCSF-PDGM-0014']...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchio as tio\n",
    "\n",
    "# Dictionary to store all the DTI FA images\n",
    "dti_fa_images = {}\n",
    "\n",
    "# Loop through each subject and load their DTI FA image\n",
    "for subject_id in subject_ids:\n",
    "    try:\n",
    "        # Construct the file path\n",
    "        folder_name = f\"{subject_id}_nifti\"\n",
    "        file_name = f\"{subject_id}_DTI_eddy_FA.nii.gz\"\n",
    "        file_path = os.path.join('.', folder_name, file_name)\n",
    "        \n",
    "        # Check if file exists\n",
    "        if os.path.exists(file_path):\n",
    "            # Load the DTI FA image\n",
    "            dti_fa_image = tio.ScalarImage(file_path)\n",
    "            \n",
    "            # Store in dictionary with subject ID as key\n",
    "            dti_fa_images[subject_id] = dti_fa_image\n",
    "            \n",
    "            #print(f\"✓ Loaded DTI FA for {subject_id}\")\n",
    "        else:\n",
    "            print(f\"✗ File not found for {subject_id}: {file_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading {subject_id}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(dti_fa_images)} DTI FA images\")\n",
    "print(f\"Subject IDs with loaded images: {list(dti_fa_images.keys())[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78dd2a2d-4cc4-46f2-8843-cc94c443bbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (501, 16)\n",
      "Columns: ['ID', 'Sex', 'Age at MRI', 'WHO CNS Grade', 'Final pathologic diagnosis (WHO 2021)', 'MGMT status', 'MGMT index', '1p/19q', 'IDH', '1-dead 0-alive', 'OS', 'EOR', 'Biopsy prior to imaging', 'BraTS21 ID', 'BraTS21 Segmentation Cohort', 'BraTS21 MGMT Cohort']\n",
      "\n",
      "First few rows:\n",
      "              ID Sex  Age at MRI  WHO CNS Grade  \\\n",
      "0  UCSF-PDGM-004   M          66              4   \n",
      "1  UCSF-PDGM-005   F          80              4   \n",
      "2  UCSF-PDGM-007   M          70              4   \n",
      "3  UCSF-PDGM-008   M          70              4   \n",
      "4  UCSF-PDGM-009   F          68              4   \n",
      "\n",
      "  Final pathologic diagnosis (WHO 2021)    MGMT status MGMT index   1p/19q  \\\n",
      "0            Glioblastoma, IDH-wildtype       negative          0  unknown   \n",
      "1            Glioblastoma, IDH-wildtype  indeterminate    unknown  unknown   \n",
      "2            Glioblastoma, IDH-wildtype  indeterminate    unknown  unknown   \n",
      "3            Glioblastoma, IDH-wildtype       negative          0  unknown   \n",
      "4            Glioblastoma, IDH-wildtype       negative          0  unknown   \n",
      "\n",
      "        IDH  1-dead 0-alive      OS     EOR Biopsy prior to imaging  \\\n",
      "0  wildtype               1  1303.0     STR                      No   \n",
      "1  wildtype               1   274.0  biopsy                      No   \n",
      "2  wildtype               1   417.0     STR                      No   \n",
      "3  wildtype               1   185.0     STR                      No   \n",
      "4  wildtype               1   389.0     STR                      No   \n",
      "\n",
      "        BraTS21 ID BraTS21 Segmentation Cohort BraTS21 MGMT Cohort  \n",
      "0  BraTS2021_00097                    Training            Training  \n",
      "1              NaN                         NaN                 NaN  \n",
      "2  BraTS2021_00103                    Training                 NaN  \n",
      "3              NaN                         NaN                 NaN  \n",
      "4  BraTS2021_00049                    Training            Training  \n",
      "\n",
      "Possible subject ID columns: ['ID', 'IDH', 'BraTS21 ID']\n",
      "Metadata shape: (501, 4)\n",
      "Columns: ['ID', 'Sex', 'Age at MRI', 'WHO CNS Grade']\n",
      "\n",
      "First few rows:\n",
      "               ID Sex  Age at MRI  WHO CNS Grade\n",
      "0  UCSF-PDGM-0004   M          66              4\n",
      "1  UCSF-PDGM-0005   F          80              4\n",
      "2  UCSF-PDGM-0007   M          70              4\n",
      "3  UCSF-PDGM-0008   M          70              4\n",
      "4  UCSF-PDGM-0009   F          68              4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the metadata\n",
    "metadata_path = '/home/jovyan/shared/data/PDGM/UCSF-PDGM-metadata_v5.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"Metadata shape: {metadata_df.shape}\")\n",
    "print(f\"Columns: {list(metadata_df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(metadata_df.head())\n",
    "\n",
    "# Check the subject ID column name\n",
    "print(f\"\\nPossible subject ID columns: {[col for col in metadata_df.columns if 'subject' in col.lower() or 'id' in col.lower()]}\")\n",
    "\n",
    "target_fields = ['ID', 'Sex', 'Age at MRI', 'WHO CNS Grade']\n",
    "\n",
    "metadata_df=metadata_df[target_fields]\n",
    "# Fix metadata ID column by zero-padding to match the structure of the scans which is 4 digits \n",
    "metadata_df['ID'] = metadata_df['ID'].apply(\n",
    "    lambda x: 'UCSF-PDGM-' + x.split('-')[-1].zfill(4)\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Metadata shape: {metadata_df.shape}\")\n",
    "print(f\"Columns: {list(metadata_df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(metadata_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111e79d5-a8a7-4ae9-952a-2ea6b01f63ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 501 TorchIO subjects\n",
      "\n",
      "Example subject: Subject(Keys: ('dti_fa', 'subject_id', 'sex', 'age', 'grade'); images: 1)\n",
      "Keys: dict_keys(['dti_fa', 'subject_id', 'sex', 'age', 'grade'])\n",
      "DTI FA shape: torch.Size([1, 240, 240, 155])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subjects = []\n",
    "\n",
    "for subject_id in dti_fa_images.keys():\n",
    "    # Find the matching row in metadata\n",
    "    row = metadata_df[metadata_df['ID'] == subject_id]\n",
    "\n",
    "    if row.empty:\n",
    "        print(f\"Subject ID {subject_id} not found in metadata.\")\n",
    "        continue  # Skip if no match found\n",
    "\n",
    "    # Extract metadata values\n",
    "    sex = row['Sex'].values[0]\n",
    "    age = row['Age at MRI'].values[0]\n",
    "    grade = int(row['WHO CNS Grade'].values[0]) - 3  # Convert to int; Grade 2: -1, 3: 0, 4: 1\n",
    "    if grade == -1:\n",
    "        grade += 1 #Grade 2: 0, Grade 3: 0, Grade 4: 1\n",
    "\n",
    "    # Create the subject dict\n",
    "    subject_dict = {\n",
    "        'dti_fa': dti_fa_images[subject_id],\n",
    "        'subject_id': subject_id,\n",
    "        'sex': sex,\n",
    "        'age': age,\n",
    "        'grade': grade\n",
    "    }\n",
    "\n",
    "    subject = tio.Subject(subject_dict)\n",
    "    subjects.append(subject)\n",
    "\n",
    "print(f\"Created {len(subjects)} TorchIO subjects\")\n",
    "\n",
    "# Check one subject\n",
    "print(f\"\\nExample subject: {subjects[0]}\")\n",
    "print(f\"Keys: {subjects[0].keys()}\")\n",
    "print(f\"DTI FA shape: {subjects[0]['dti_fa'].data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c6412b-3c26-4f78-b23d-f8d37d801ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SubjectsDataset\n",
    "\n",
    "SubjectsDataset = tio.SubjectsDataset(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce6d633-7319-44fd-bf04-638d41862368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dti_fa: ScalarImage(shape: (1, 240, 240, 155); spacing: (1.00, 1.00, 1.00); orientation: LPS+; dtype: torch.FloatTensor; memory: 34.1 MiB)\n",
      "subject_id: UCSF-PDGM-0257\n",
      "sex: M\n",
      "age: 32\n",
      "grade: 0\n"
     ]
    }
   ],
   "source": [
    "#Performing a manual check \n",
    "print(\"dti_fa:\", SubjectsDataset[221]['dti_fa'])\n",
    "print(\"subject_id:\", SubjectsDataset[221]['subject_id'])\n",
    "print(\"sex:\", SubjectsDataset[221]['sex'])\n",
    "print(\"age:\", SubjectsDataset[221]['age'])\n",
    "print(\"grade:\", SubjectsDataset[221]['grade'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1885658-bcf0-4097-adbf-44cce89959f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This a dataframe of 5 Male/5 Female for Grade 2, 3, 4\n",
    "selected_subject_ids = [\n",
    "    'UCSF-PDGM-0004', 'UCSF-PDGM-0005', 'UCSF-PDGM-0241', 'UCSF-PDGM-0231', 'UCSF-PDGM-0327',\n",
    "    'UCSF-PDGM-0305', 'UCSF-PDGM-0007', 'UCSF-PDGM-0009', 'UCSF-PDGM-0243', 'UCSF-PDGM-0254',\n",
    "    'UCSF-PDGM-0439', 'UCSF-PDGM-0351', 'UCSF-PDGM-0008', 'UCSF-PDGM-0011', 'UCSF-PDGM-0249',\n",
    "    'UCSF-PDGM-0268', 'UCSF-PDGM-0444', 'UCSF-PDGM-0438', 'UCSF-PDGM-0010', 'UCSF-PDGM-0012',\n",
    "    'UCSF-PDGM-0251', 'UCSF-PDGM-0274', 'UCSF-PDGM-0448', 'UCSF-PDGM-0442', 'UCSF-PDGM-0015',\n",
    "    'UCSF-PDGM-0013', 'UCSF-PDGM-0262', 'UCSF-PDGM-0277', 'UCSF-PDGM-0456', 'UCSF-PDGM-0443',\n",
    "    'UCSF-PDGM-0017', 'UCSF-PDGM-0014', 'UCSF-PDGM-0263', 'UCSF-PDGM-0282', 'UCSF-PDGM-0465',\n",
    "    'UCSF-PDGM-0446', 'UCSF-PDGM-0018', 'UCSF-PDGM-0016', 'UCSF-PDGM-0272', 'UCSF-PDGM-0285',\n",
    "    'UCSF-PDGM-0478', 'UCSF-PDGM-0475', 'UCSF-PDGM-0020', 'UCSF-PDGM-0019', 'UCSF-PDGM-0499',\n",
    "    'UCSF-PDGM-0326', 'UCSF-PDGM-0483', 'UCSF-PDGM-0476', 'UCSF-PDGM-0021', 'UCSF-PDGM-0022',\n",
    "    'UCSF-PDGM-0500', 'UCSF-PDGM-0357', 'UCSF-PDGM-0485', 'UCSF-PDGM-0477', 'UCSF-PDGM-0024',\n",
    "    'UCSF-PDGM-0023', 'UCSF-PDGM-0501', 'UCSF-PDGM-0367', 'UCSF-PDGM-0490', 'UCSF-PDGM-0540'\n",
    "]\n",
    "Subjects_small = [\n",
    "    subj for subj in subjects if subj['subject_id'] in selected_subject_ids\n",
    "]\n",
    "SubjectsDataset_small = tio.SubjectsDataset(Subjects_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f62ea9b5-64af-401a-a03a-4cf83432a594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dti_fa: ScalarImage(shape: (1, 240, 240, 155); spacing: (1.00, 1.00, 1.00); orientation: LPS+; dtype: torch.FloatTensor; memory: 34.1 MiB)\n",
      "subject_id: UCSF-PDGM-0231\n",
      "sex: F\n",
      "age: 36\n",
      "grade: 0\n"
     ]
    }
   ],
   "source": [
    "#Performing a manual check \n",
    "print(\"dti_fa:\", SubjectsDataset_small[20]['dti_fa'])\n",
    "print(\"subject_id:\", SubjectsDataset_small[20]['subject_id'])\n",
    "print(\"sex:\", SubjectsDataset_small[20]['sex'])\n",
    "print(\"age:\", SubjectsDataset_small[20]['age'])\n",
    "print(\"grade:\", SubjectsDataset_small[20]['grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a855fa-b041-43ef-aa19-d4927a36324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 155, 240, 240])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_subjects(batch):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for s in batch:\n",
    "        img = s['dti_fa'].data  # shape: (1, H, W, D)\n",
    "        img = img.permute(0, 3, 1, 2)  # shape: (1, D, H, W)\n",
    "        images.append(img)\n",
    "        labels.append(s['grade'])\n",
    "    images = torch.stack(images)  # (B, 1, D, H, W)\n",
    "    labels = torch.tensor(labels)  # (B,)\n",
    "    return images, labels  # <- this was misplaced\n",
    "\n",
    "# DataLoader using the custom collate function\n",
    "train_loader = DataLoader(\n",
    "    SubjectsDataset_small, \n",
    "    batch_size=1, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_subjects\n",
    ")\n",
    "\n",
    "# Test output shape\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)  # should be [6, 1, 155, 240, 240]\n",
    "    print(labels.shape)  # should be [6]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2fb6e70-e220-4034-8a99-8adfce6548c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.chdir('/home/jovyan/git-gliograde/Deep_Learning')\n",
    "from resnet import generate_model\n",
    "\n",
    "model = generate_model(\n",
    "    model_depth=10,\n",
    "    n_classes=2,          # We are using a 2-class solution now \n",
    "    n_input_channels=1    # set to 1 for grayscale or 3 for RGB\n",
    ")\n",
    "\n",
    "#print(model)\n",
    "os.chdir('/home/jovyan/shared/data/PDGM/UCSF-PDGM-v5/UCSF-PDGM-v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "205a4cdb-9b3a-41bf-a6e4-56a03c404248",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85fc82ef-85ad-4936-ad01-dad47ef2066e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc8a7d7-4c8f-4683-8c3d-bce48519f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 43.8285\n",
      "Epoch 2, Loss: 43.2488\n",
      "Epoch 3, Loss: 42.3346\n",
      "Epoch 4, Loss: 38.9665\n",
      "Epoch 5, Loss: 52.3800\n",
      "Epoch 6, Loss: 40.9311\n",
      "Epoch 7, Loss: 43.2322\n",
      "Epoch 8, Loss: 41.2701\n",
      "Epoch 9, Loss: 39.8346\n",
      "Epoch 10, Loss: 38.3635\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "for epoch in range(10):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92114951-7478-4c5e-b246-88d7d9dac25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "FINAL EVALUATION\n",
      "==============================\n",
      "Training Accuracy: 40/60 = 0.667 (66.7%)\n",
      "✓ Pipeline working!\n"
     ]
    }
   ],
   "source": [
    "# Simple final evaluation\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate and display results\n",
    "correct = sum([pred == label for pred, label in zip(all_preds, all_labels)])\n",
    "total = len(all_labels)\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"Training Accuracy: {correct}/{total} = {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "print(\"✓ Pipeline working!\" if accuracy > 0.5 else \"⚠ Check pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b84a9e-a584-41b0-b704-28291cb628ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for all subjects:\n",
      "==================================================\n",
      "Sample | True Grade | Predicted Grade\n",
      "-----------------------------------\n",
      "     1 |          0 |               0\n",
      "     2 |          0 |               0\n",
      "     3 |          0 |               0\n",
      "     4 |          1 |               0\n",
      "     5 |          0 |               0\n",
      "     6 |          0 |               0\n",
      "     7 |          0 |               0\n",
      "     8 |          0 |               0\n",
      "     9 |          0 |               0\n",
      "    10 |          1 |               0\n",
      "    11 |          1 |               0\n",
      "    12 |          0 |               0\n",
      "    13 |          1 |               0\n",
      "    14 |          0 |               0\n",
      "    15 |          0 |               0\n",
      "    16 |          1 |               0\n",
      "    17 |          0 |               0\n",
      "    18 |          1 |               0\n",
      "    19 |          0 |               0\n",
      "    20 |          1 |               0\n",
      "    21 |          0 |               0\n",
      "    22 |          0 |               0\n",
      "    23 |          0 |               0\n",
      "    24 |          1 |               0\n",
      "    25 |          1 |               0\n",
      "    26 |          1 |               0\n",
      "    27 |          0 |               0\n",
      "    28 |          1 |               0\n",
      "    29 |          0 |               0\n",
      "    30 |          0 |               0\n",
      "    31 |          0 |               0\n",
      "    32 |          0 |               0\n",
      "    33 |          1 |               0\n",
      "    34 |          0 |               0\n",
      "    35 |          1 |               0\n",
      "    36 |          1 |               0\n",
      "    37 |          0 |               0\n",
      "    38 |          0 |               0\n",
      "    39 |          0 |               0\n",
      "    40 |          0 |               0\n",
      "    41 |          1 |               0\n",
      "    42 |          0 |               0\n",
      "    43 |          0 |               0\n",
      "    44 |          1 |               0\n",
      "    45 |          0 |               0\n",
      "    46 |          1 |               0\n",
      "    47 |          0 |               0\n",
      "    48 |          0 |               0\n",
      "    49 |          1 |               0\n",
      "    50 |          0 |               0\n",
      "    51 |          0 |               0\n",
      "    52 |          0 |               0\n",
      "    53 |          0 |               0\n",
      "    54 |          0 |               0\n",
      "    55 |          1 |               0\n",
      "    56 |          0 |               0\n",
      "    57 |          1 |               0\n",
      "    58 |          0 |               0\n",
      "    59 |          0 |               0\n",
      "    60 |          0 |               0\n",
      "==================================================\n",
      "\n",
      "SUMMARY:\n",
      "Total samples: 60\n",
      "True labels used: [0, 1]\n",
      "Predicted labels: [0]\n",
      "\n",
      "True label distribution:\n",
      "  Grade 0: 40 samples\n",
      "  Grade 1: 20 samples\n",
      "\n",
      "Predicted label distribution:\n",
      "  Grade 0: 60 samples\n",
      "\n",
      "🚨 WARNING: Model is predicting ONLY Grade 0 for ALL samples!\n",
      "This means the model hasn't learned to distinguish between classes.\n",
      "\n",
      "Accuracy: 40/60 = 0.667 (66.7%)\n"
     ]
    }
   ],
   "source": [
    "# Simple prediction analysis - just print all predictions vs true labels\n",
    "\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "sample_count = 0\n",
    "\n",
    "print(\"Predictions for all subjects:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Sample | True Grade | Predicted Grade\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        # Print each sample in this batch\n",
    "        for i in range(len(labels)):\n",
    "            sample_count += 1\n",
    "            true_grade = labels[i].item()\n",
    "            pred_grade = predictions[i].item()\n",
    "            \n",
    "            print(f\"{sample_count:6d} | {true_grade:10d} | {pred_grade:15d}\")\n",
    "            \n",
    "            all_predictions.append(pred_grade)\n",
    "            all_labels.append(true_grade)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Summary\n",
    "unique_predictions = set(all_predictions)\n",
    "unique_labels = set(all_labels)\n",
    "\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"Total samples: {len(all_labels)}\")\n",
    "print(f\"True labels used: {sorted(unique_labels)}\")\n",
    "print(f\"Predicted labels: {sorted(unique_predictions)}\")\n",
    "\n",
    "# Count predictions\n",
    "from collections import Counter\n",
    "pred_counts = Counter(all_predictions)\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "print(f\"\\nTrue label distribution:\")\n",
    "for grade in sorted(label_counts.keys()):\n",
    "    print(f\"  Grade {grade}: {label_counts[grade]} samples\")\n",
    "\n",
    "print(f\"\\nPredicted label distribution:\")\n",
    "for grade in sorted(pred_counts.keys()):\n",
    "    print(f\"  Grade {grade}: {pred_counts[grade]} samples\")\n",
    "\n",
    "# Check if predicting only one class\n",
    "if len(unique_predictions) == 1:\n",
    "    print(f\"\\n🚨 WARNING: Model is predicting ONLY Grade {list(unique_predictions)[0]} for ALL samples!\")\n",
    "    print(\"This means the model hasn't learned to distinguish between classes.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Model is predicting {len(unique_predictions)} different classes\")\n",
    "\n",
    "# Accuracy\n",
    "correct = sum([p == l for p, l in zip(all_predictions, all_labels)])\n",
    "accuracy = correct / len(all_labels)\n",
    "print(f\"\\nAccuracy: {correct}/{len(all_labels)} = {accuracy:.3f} ({accuracy*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21e4ca-a7d5-4489-b113-510d1532dcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
