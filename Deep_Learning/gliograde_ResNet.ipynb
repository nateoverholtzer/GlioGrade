{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8ec5a4-ddab-499b-978d-308bd1f9d93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working from: /home/jovyan/shared/data/PDGM/UCSF-PDGM-v5/UCSF-PDGM-v5\n",
      "Extracting subject IDs...\n",
      "==================================================\n",
      "Found 501 subjects:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchio as tio\n",
    "\n",
    "# Set the base directory\n",
    "base_path = '/home/jovyan/shared/data/PDGM/UCSF-PDGM-v5/UCSF-PDGM-v5'\n",
    "os.chdir(base_path)\n",
    "\n",
    "print(f\"Working from: {os.getcwd()}\")\n",
    "print(\"Extracting subject IDs...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get all subject directories and extract IDs\n",
    "subject_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and 'UCSF-PDGM-' in d and '_nifti' in d]\n",
    "\n",
    "# Extract clean subject IDs\n",
    "subject_ids = []\n",
    "for subject_dir in subject_dirs:\n",
    "    # Remove '_nifti' suffix to get clean ID\n",
    "    subject_id = subject_dir.replace('_nifti', '')\n",
    "    subject_ids.append(subject_id)\n",
    "\n",
    "# Sort the subject IDs\n",
    "subject_ids.sort()\n",
    "\n",
    "print(f\"Found {len(subject_ids)} subjects:\")\n",
    "#print(\"=\" * 30)\n",
    "#for i, subject_id in enumerate(subject_ids, 1):\n",
    "#    print(f\"{i:2d}. {subject_id}\")\n",
    "\n",
    "#print(f\"\\nTotal subjects: {len(subject_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "300692b8-9159-4dab-8f09-9743f257350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 501 DTI FA images\n",
      "Subject IDs with loaded images: ['UCSF-PDGM-0004', 'UCSF-PDGM-0005', 'UCSF-PDGM-0007', 'UCSF-PDGM-0008', 'UCSF-PDGM-0009', 'UCSF-PDGM-0010', 'UCSF-PDGM-0011', 'UCSF-PDGM-0012', 'UCSF-PDGM-0013', 'UCSF-PDGM-0014']...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchio as tio\n",
    "\n",
    "# Dictionary to store all the DTI FA images\n",
    "dti_fa_images = {}\n",
    "\n",
    "# Loop through each subject and load their DTI FA image\n",
    "for subject_id in subject_ids:\n",
    "    try:\n",
    "        # Construct the file path\n",
    "        folder_name = f\"{subject_id}_nifti\"\n",
    "        file_name = f\"{subject_id}_DTI_eddy_FA.nii.gz\"\n",
    "        file_path = os.path.join('.', folder_name, file_name)\n",
    "        \n",
    "        # Check if file exists\n",
    "        if os.path.exists(file_path):\n",
    "            # Load the DTI FA image\n",
    "            dti_fa_image = tio.ScalarImage(file_path)\n",
    "            \n",
    "            # Store in dictionary with subject ID as key\n",
    "            dti_fa_images[subject_id] = dti_fa_image\n",
    "            \n",
    "            #print(f\"✓ Loaded DTI FA for {subject_id}\")\n",
    "        else:\n",
    "            print(f\"✗ File not found for {subject_id}: {file_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading {subject_id}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(dti_fa_images)} DTI FA images\")\n",
    "print(f\"Subject IDs with loaded images: {list(dti_fa_images.keys())[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78dd2a2d-4cc4-46f2-8843-cc94c443bbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (501, 16)\n",
      "Columns: ['ID', 'Sex', 'Age at MRI', 'WHO CNS Grade', 'Final pathologic diagnosis (WHO 2021)', 'MGMT status', 'MGMT index', '1p/19q', 'IDH', '1-dead 0-alive', 'OS', 'EOR', 'Biopsy prior to imaging', 'BraTS21 ID', 'BraTS21 Segmentation Cohort', 'BraTS21 MGMT Cohort']\n",
      "\n",
      "First few rows:\n",
      "              ID Sex  Age at MRI  WHO CNS Grade  \\\n",
      "0  UCSF-PDGM-004   M          66              4   \n",
      "1  UCSF-PDGM-005   F          80              4   \n",
      "2  UCSF-PDGM-007   M          70              4   \n",
      "3  UCSF-PDGM-008   M          70              4   \n",
      "4  UCSF-PDGM-009   F          68              4   \n",
      "\n",
      "  Final pathologic diagnosis (WHO 2021)    MGMT status MGMT index   1p/19q  \\\n",
      "0            Glioblastoma, IDH-wildtype       negative          0  unknown   \n",
      "1            Glioblastoma, IDH-wildtype  indeterminate    unknown  unknown   \n",
      "2            Glioblastoma, IDH-wildtype  indeterminate    unknown  unknown   \n",
      "3            Glioblastoma, IDH-wildtype       negative          0  unknown   \n",
      "4            Glioblastoma, IDH-wildtype       negative          0  unknown   \n",
      "\n",
      "        IDH  1-dead 0-alive      OS     EOR Biopsy prior to imaging  \\\n",
      "0  wildtype               1  1303.0     STR                      No   \n",
      "1  wildtype               1   274.0  biopsy                      No   \n",
      "2  wildtype               1   417.0     STR                      No   \n",
      "3  wildtype               1   185.0     STR                      No   \n",
      "4  wildtype               1   389.0     STR                      No   \n",
      "\n",
      "        BraTS21 ID BraTS21 Segmentation Cohort BraTS21 MGMT Cohort  \n",
      "0  BraTS2021_00097                    Training            Training  \n",
      "1              NaN                         NaN                 NaN  \n",
      "2  BraTS2021_00103                    Training                 NaN  \n",
      "3              NaN                         NaN                 NaN  \n",
      "4  BraTS2021_00049                    Training            Training  \n",
      "\n",
      "Possible subject ID columns: ['ID', 'IDH', 'BraTS21 ID']\n",
      "Metadata shape: (501, 4)\n",
      "Columns: ['ID', 'Sex', 'Age at MRI', 'WHO CNS Grade']\n",
      "\n",
      "First few rows:\n",
      "               ID Sex  Age at MRI  WHO CNS Grade\n",
      "0  UCSF-PDGM-0004   M          66              4\n",
      "1  UCSF-PDGM-0005   F          80              4\n",
      "2  UCSF-PDGM-0007   M          70              4\n",
      "3  UCSF-PDGM-0008   M          70              4\n",
      "4  UCSF-PDGM-0009   F          68              4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the metadata\n",
    "metadata_path = '/home/jovyan/shared/data/PDGM/UCSF-PDGM-metadata_v5.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"Metadata shape: {metadata_df.shape}\")\n",
    "print(f\"Columns: {list(metadata_df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(metadata_df.head())\n",
    "\n",
    "# Check the subject ID column name\n",
    "print(f\"\\nPossible subject ID columns: {[col for col in metadata_df.columns if 'subject' in col.lower() or 'id' in col.lower()]}\")\n",
    "\n",
    "target_fields = ['ID', 'Sex', 'Age at MRI', 'WHO CNS Grade']\n",
    "\n",
    "metadata_df=metadata_df[target_fields]\n",
    "# Fix metadata ID column by zero-padding to match the structure of the scans which is 4 digits \n",
    "metadata_df['ID'] = metadata_df['ID'].apply(\n",
    "    lambda x: 'UCSF-PDGM-' + x.split('-')[-1].zfill(4)\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Metadata shape: {metadata_df.shape}\")\n",
    "print(f\"Columns: {list(metadata_df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(metadata_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111e79d5-a8a7-4ae9-952a-2ea6b01f63ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 501 TorchIO subjects\n",
      "\n",
      "Example subject: Subject(Keys: ('dti_fa', 'subject_id', 'sex', 'age', 'grade'); images: 1)\n",
      "Keys: dict_keys(['dti_fa', 'subject_id', 'sex', 'age', 'grade'])\n",
      "DTI FA shape: torch.Size([1, 240, 240, 155])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subjects = []\n",
    "\n",
    "for subject_id in dti_fa_images.keys():\n",
    "    # Find the matching row in metadata\n",
    "    row = metadata_df[metadata_df['ID'] == subject_id]\n",
    "\n",
    "    if row.empty:\n",
    "        print(f\"Subject ID {subject_id} not found in metadata.\")\n",
    "        continue  # Skip if no match found\n",
    "\n",
    "    # Extract metadata values\n",
    "    sex = row['Sex'].values[0]\n",
    "    age = row['Age at MRI'].values[0]\n",
    "    grade = int(row['WHO CNS Grade'].values[0]) - 3  # Convert to int; Grade 2: -1, 3: 0, 4: 1\n",
    "    if grade == -1:\n",
    "        grade += 1 #Grade 2: 0, Grade 3: 0, Grade 4: 1\n",
    "\n",
    "    # Create the subject dict\n",
    "    subject_dict = {\n",
    "        'dti_fa': dti_fa_images[subject_id],\n",
    "        'subject_id': subject_id,\n",
    "        'sex': sex,\n",
    "        'age': age,\n",
    "        'grade': grade\n",
    "    }\n",
    "\n",
    "    subject = tio.Subject(subject_dict)\n",
    "    subjects.append(subject)\n",
    "\n",
    "print(f\"Created {len(subjects)} TorchIO subjects\")\n",
    "\n",
    "# Check one subject\n",
    "print(f\"\\nExample subject: {subjects[0]}\")\n",
    "print(f\"Keys: {subjects[0].keys()}\")\n",
    "print(f\"DTI FA shape: {subjects[0]['dti_fa'].data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c6412b-3c26-4f78-b23d-f8d37d801ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SubjectsDataset\n",
    "\n",
    "SubjectsDataset = tio.SubjectsDataset(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce6d633-7319-44fd-bf04-638d41862368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dti_fa: ScalarImage(shape: (1, 240, 240, 155); spacing: (1.00, 1.00, 1.00); orientation: LPS+; dtype: torch.FloatTensor; memory: 34.1 MiB)\n",
      "subject_id: UCSF-PDGM-0257\n",
      "sex: M\n",
      "age: 32\n",
      "grade: 1\n"
     ]
    }
   ],
   "source": [
    "#Performing a manual check \n",
    "print(\"dti_fa:\", SubjectsDataset[221]['dti_fa'])\n",
    "print(\"subject_id:\", SubjectsDataset[221]['subject_id'])\n",
    "print(\"sex:\", SubjectsDataset[221]['sex'])\n",
    "print(\"age:\", SubjectsDataset[221]['age'])\n",
    "print(\"grade:\", SubjectsDataset[20]['grade'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1885658-bcf0-4097-adbf-44cce89959f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This a dataframe of 5 Male/5 Female for Grade 2, 3, 4\n",
    "# Train set subject IDs - extracted from UCSF-PDGM dataset\n",
    "# Format: Full UCSF-PDGM- prefix with 4-digit numbers\n",
    "\n",
    "selected_subject_ids = [\n",
    "    \"UCSF-PDGM-0399\", \"UCSF-PDGM-0389\", \"UCSF-PDGM-0137\", \"UCSF-PDGM-0093\", \"UCSF-PDGM-0026\", \n",
    "    \"UCSF-PDGM-0474\", \"UCSF-PDGM-0375\", \"UCSF-PDGM-0031\", \"UCSF-PDGM-0480\", \"UCSF-PDGM-0264\",\n",
    "    \"UCSF-PDGM-0514\", \"UCSF-PDGM-0077\", \"UCSF-PDGM-0044\", \"UCSF-PDGM-0454\", \"UCSF-PDGM-0432\", \n",
    "    \"UCSF-PDGM-0069\", \"UCSF-PDGM-0023\", \"UCSF-PDGM-0205\", \"UCSF-PDGM-0234\", \"UCSF-PDGM-0390\",\n",
    "    \"UCSF-PDGM-0338\", \"UCSF-PDGM-0095\", \"UCSF-PDGM-0427\", \"UCSF-PDGM-0396\", \"UCSF-PDGM-0128\", \n",
    "    \"UCSF-PDGM-0382\", \"UCSF-PDGM-0213\", \"UCSF-PDGM-0539\", \"UCSF-PDGM-0180\", \"UCSF-PDGM-0396\",\n",
    "    \"UCSF-PDGM-0433\", \"UCSF-PDGM-0215\", \"UCSF-PDGM-0367\", \"UCSF-PDGM-0121\", \"UCSF-PDGM-0297\", \n",
    "    \"UCSF-PDGM-0461\", \"UCSF-PDGM-0298\", \"UCSF-PDGM-0341\", \"UCSF-PDGM-0018\", \"UCSF-PDGM-0236\",\n",
    "    \"UCSF-PDGM-0178\", \"UCSF-PDGM-0168\", \"UCSF-PDGM-0273\", \"UCSF-PDGM-0413\", \"UCSF-PDGM-0455\", \n",
    "    \"UCSF-PDGM-0312\", \"UCSF-PDGM-0237\", \"UCSF-PDGM-0250\", \"UCSF-PDGM-0066\", \"UCSF-PDGM-0509\",\n",
    "    \"UCSF-PDGM-0380\", \"UCSF-PDGM-0494\", \"UCSF-PDGM-0362\", \"UCSF-PDGM-0207\", \"UCSF-PDGM-0541\", \n",
    "    \"UCSF-PDGM-0240\", \"UCSF-PDGM-0104\", \"UCSF-PDGM-0127\", \"UCSF-PDGM-0491\", \"UCSF-PDGM-0210\",\n",
    "    \"UCSF-PDGM-0188\", \"UCSF-PDGM-0426\", \"UCSF-PDGM-0123\", \"UCSF-PDGM-0379\", \"UCSF-PDGM-0453\", \n",
    "    \"UCSF-PDGM-0243\", \"UCSF-PDGM-0112\", \"UCSF-PDGM-0510\", \"UCSF-PDGM-0134\", \"UCSF-PDGM-0372\",\n",
    "    \"UCSF-PDGM-0516\", \"UCSF-PDGM-0448\", \"UCSF-PDGM-0331\", \"UCSF-PDGM-0320\", \"UCSF-PDGM-0140\", \n",
    "    \"UCSF-PDGM-0103\", \"UCSF-PDGM-0008\", \"UCSF-PDGM-0045\", \"UCSF-PDGM-0495\", \"UCSF-PDGM-0371\",\n",
    "    \"UCSF-PDGM-0456\", \"UCSF-PDGM-0156\", \"UCSF-PDGM-0013\", \"UCSF-PDGM-0321\", \"UCSF-PDGM-0158\", \n",
    "    \"UCSF-PDGM-0465\", \"UCSF-PDGM-0525\", \"UCSF-PDGM-0536\", \"UCSF-PDGM-0251\", \"UCSF-PDGM-0204\",\n",
    "    \"UCSF-PDGM-0318\", \"UCSF-PDGM-0165\", \"UCSF-PDGM-0197\", \"UCSF-PDGM-0530\", \"UCSF-PDGM-0470\", \n",
    "    \"UCSF-PDGM-0116\", \"UCSF-PDGM-0447\", \"UCSF-PDGM-0420\", \"UCSF-PDGM-0022\", \"UCSF-PDGM-0194\",\n",
    "    \"UCSF-PDGM-0187\", \"UCSF-PDGM-0346\", \"UCSF-PDGM-0203\", \"UCSF-PDGM-0521\", \"UCSF-PDGM-0126\", \n",
    "    \"UCSF-PDGM-0458\", \"UCSF-PDGM-0307\", \"UCSF-PDGM-0102\", \"UCSF-PDGM-0468\", \"UCSF-PDGM-0279\",\n",
    "    \"UCSF-PDGM-0065\", \"UCSF-PDGM-0037\", \"UCSF-PDGM-0043\", \"UCSF-PDGM-0374\", \"UCSF-PDGM-0135\", \n",
    "    \"UCSF-PDGM-0336\", \"UCSF-PDGM-0340\", \"UCSF-PDGM-0029\", \"UCSF-PDGM-0238\", \"UCSF-PDGM-0378\",\n",
    "    \"UCSF-PDGM-0487\", \"UCSF-PDGM-0287\", \"UCSF-PDGM-0170\", \"UCSF-PDGM-0508\", \"UCSF-PDGM-0532\", \n",
    "    \"UCSF-PDGM-0522\", \"UCSF-PDGM-0198\", \"UCSF-PDGM-0506\", \"UCSF-PDGM-0024\", \"UCSF-PDGM-0162\",\n",
    "    \"UCSF-PDGM-0429\", \"UCSF-PDGM-0223\", \"UCSF-PDGM-0489\", \"UCSF-PDGM-0078\", \"UCSF-PDGM-0075\", \n",
    "    \"UCSF-PDGM-0173\", \"UCSF-PDGM-0157\", \"UCSF-PDGM-0233\", \"UCSF-PDGM-0387\", \"UCSF-PDGM-0467\",\n",
    "    \"UCSF-PDGM-0436\", \"UCSF-PDGM-0186\", \"UCSF-PDGM-0119\", \"UCSF-PDGM-0099\", \"UCSF-PDGM-0323\", \n",
    "    \"UCSF-PDGM-0020\", \"UCSF-PDGM-0042\", \"UCSF-PDGM-0291\", \"UCSF-PDGM-0086\", \"UCSF-PDGM-0512\",\n",
    "    \"UCSF-PDGM-0449\", \"UCSF-PDGM-0150\", \"UCSF-PDGM-0183\", \"UCSF-PDGM-0457\", \"UCSF-PDGM-0088\", \n",
    "    \"UCSF-PDGM-0159\", \"UCSF-PDGM-0272\", \"UCSF-PDGM-0423\", \"UCSF-PDGM-0393\", \"UCSF-PDGM-0476\",\n",
    "    \"UCSF-PDGM-0245\", \"UCSF-PDGM-0460\", \"UCSF-PDGM-0247\", \"UCSF-PDGM-0499\", \"UCSF-PDGM-0057\", \n",
    "    \"UCSF-PDGM-0083\", \"UCSF-PDGM-0445\", \"UCSF-PDGM-0364\", \"UCSF-PDGM-0144\", \"UCSF-PDGM-0383\",\n",
    "    \"UCSF-PDGM-0106\", \"UCSF-PDGM-0353\", \"UCSF-PDGM-0483\", \"UCSF-PDGM-0053\", \"UCSF-PDGM-0517\", \n",
    "    \"UCSF-PDGM-0524\", \"UCSF-PDGM-0410\", \"UCSF-PDGM-0477\", \"UCSF-PDGM-0231\", \"UCSF-PDGM-0059\",\n",
    "    \"UCSF-PDGM-0089\", \"UCSF-PDGM-0070\", \"UCSF-PDGM-0519\", \"UCSF-PDGM-0155\", \"UCSF-PDGM-0409\", \n",
    "    \"UCSF-PDGM-0497\", \"UCSF-PDGM-0261\", \"UCSF-PDGM-0440\", \"UCSF-PDGM-0118\", \"UCSF-PDGM-0282\",\n",
    "    \"UCSF-PDGM-0252\", \"UCSF-PDGM-0406\", \"UCSF-PDGM-0490\", \"UCSF-PDGM-0164\", \"UCSF-PDGM-0400\", \n",
    "    \"UCSF-PDGM-0357\", \"UCSF-PDGM-0209\", \"UCSF-PDGM-0300\", \"UCSF-PDGM-0091\", \"UCSF-PDGM-0344\",\n",
    "    \"UCSF-PDGM-0347\", \"UCSF-PDGM-0475\", \"UCSF-PDGM-0469\", \"UCSF-PDGM-0246\", \"UCSF-PDGM-0309\", \n",
    "    \"UCSF-PDGM-0039\", \"UCSF-PDGM-0071\", \"UCSF-PDGM-0174\", \"UCSF-PDGM-0397\", \"UCSF-PDGM-0011\",\n",
    "    \"UCSF-PDGM-0132\", \"UCSF-PDGM-0471\", \"UCSF-PDGM-0441\", \"UCSF-PDGM-0161\", \"UCSF-PDGM-0016\", \n",
    "    \"UCSF-PDGM-0105\", \"UCSF-PDGM-0479\", \"UCSF-PDGM-0425\", \"UCSF-PDGM-0193\", \"UCSF-PDGM-0412\",\n",
    "    \"UCSF-PDGM-0196\", \"UCSF-PDGM-0094\", \"UCSF-PDGM-0424\", \"UCSF-PDGM-0444\", \"UCSF-PDGM-0358\", \n",
    "    \"UCSF-PDGM-0146\", \"UCSF-PDGM-0286\", \"UCSF-PDGM-0534\", \"UCSF-PDGM-0349\", \"UCSF-PDGM-0416\",\n",
    "    \"UCSF-PDGM-0329\", \"UCSF-PDGM-0526\", \"UCSF-PDGM-0130\", \"UCSF-PDGM-0087\", \"UCSF-PDGM-0360\", \n",
    "    \"UCSF-PDGM-0265\", \"UCSF-PDGM-0021\", \"UCSF-PDGM-0004\", \"UCSF-PDGM-0419\", \"UCSF-PDGM-0384\",\n",
    "    \"UCSF-PDGM-0411\", \"UCSF-PDGM-0498\", \"UCSF-PDGM-0253\", \"UCSF-PDGM-0431\", \"UCSF-PDGM-0527\", \n",
    "    \"UCSF-PDGM-0451\", \"UCSF-PDGM-0032\", \"UCSF-PDGM-0502\", \"UCSF-PDGM-0513\", \"UCSF-PDGM-0228\",\n",
    "    \"UCSF-PDGM-0302\", \"UCSF-PDGM-0014\", \"UCSF-PDGM-0274\", \"UCSF-PDGM-0147\", \"UCSF-PDGM-0283\", \n",
    "    \"UCSF-PDGM-0027\", \"UCSF-PDGM-0227\", \"UCSF-PDGM-0281\", \"UCSF-PDGM-0270\", \"UCSF-PDGM-0501\",\n",
    "    \"UCSF-PDGM-0266\", \"UCSF-PDGM-0096\", \"UCSF-PDGM-0143\", \"UCSF-PDGM-0064\", \"UCSF-PDGM-0131\", \n",
    "    \"UCSF-PDGM-0538\", \"UCSF-PDGM-0462\", \"UCSF-PDGM-0067\", \"UCSF-PDGM-0417\", \"UCSF-PDGM-0202\",\n",
    "    \"UCSF-PDGM-0407\", \"UCSF-PDGM-0368\", \"UCSF-PDGM-0342\", \"UCSF-PDGM-0260\", \"UCSF-PDGM-0225\", \n",
    "    \"UCSF-PDGM-0313\", \"UCSF-PDGM-0079\", \"UCSF-PDGM-0330\", \"UCSF-PDGM-0343\", \"UCSF-PDGM-0232\",\n",
    "    \"UCSF-PDGM-0074\", \"UCSF-PDGM-0268\", \"UCSF-PDGM-0025\", \"UCSF-PDGM-0369\", \"UCSF-PDGM-0418\", \n",
    "    \"UCSF-PDGM-0185\", \"UCSF-PDGM-0055\", \"UCSF-PDGM-0084\", \"UCSF-PDGM-0392\", \"UCSF-PDGM-0348\",\n",
    "    \"UCSF-PDGM-0166\", \"UCSF-PDGM-0114\", \"UCSF-PDGM-0206\", \"UCSF-PDGM-0409\", \"UCSF-PDGM-0136\", \n",
    "    \"UCSF-PDGM-0311\", \"UCSF-PDGM-0500\", \"UCSF-PDGM-0335\", \"UCSF-PDGM-0345\", \"UCSF-PDGM-0405\",\n",
    "    \"UCSF-PDGM-0355\", \"UCSF-PDGM-0142\", \"UCSF-PDGM-0276\", \"UCSF-PDGM-0485\", \"UCSF-PDGM-0256\", \n",
    "    \"UCSF-PDGM-0459\", \"UCSF-PDGM-0373\", \"UCSF-PDGM-0529\", \"UCSF-PDGM-0214\", \"UCSF-PDGM-0484\",\n",
    "    \"UCSF-PDGM-0398\", \"UCSF-PDGM-0107\", \"UCSF-PDGM-0308\", \"UCSF-PDGM-0325\", \"UCSF-PDGM-0169\", \n",
    "    \"UCSF-PDGM-0277\", \"UCSF-PDGM-0446\", \"UCSF-PDGM-0450\", \"UCSF-PDGM-0350\", \"UCSF-PDGM-0167\",\n",
    "    \"UCSF-PDGM-0030\", \"UCSF-PDGM-0048\", \"UCSF-PDGM-0518\", \"UCSF-PDGM-0139\", \"UCSF-PDGM-0101\", \n",
    "    \"UCSF-PDGM-0422\", \"UCSF-PDGM-0520\", \"UCSF-PDGM-0080\", \"UCSF-PDGM-0438\", \"UCSF-PDGM-0452\",\n",
    "    \"UCSF-PDGM-0366\", \"UCSF-PDGM-0258\", \"UCSF-PDGM-0473\", \"UCSF-PDGM-0381\", \"UCSF-PDGM-0428\", \n",
    "    \"UCSF-PDGM-0535\", \"UCSF-PDGM-0242\", \"UCSF-PDGM-0063\", \"UCSF-PDGM-0303\", \"UCSF-PDGM-0082\",\n",
    "    \"UCSF-PDGM-0129\", \"UCSF-PDGM-0352\", \"UCSF-PDGM-0334\", \"UCSF-PDGM-0505\", \"UCSF-PDGM-0153\", \n",
    "    \"UCSF-PDGM-0288\", \"UCSF-PDGM-0326\", \"UCSF-PDGM-0068\", \"UCSF-PDGM-0435\", \"UCSF-PDGM-0402\",\n",
    "    \"UCSF-PDGM-0442\", \"UCSF-PDGM-0503\", \"UCSF-PDGM-0363\", \"UCSF-PDGM-0537\", \"UCSF-PDGM-0090\", \n",
    "    \"UCSF-PDGM-0365\", \"UCSF-PDGM-0176\", \"UCSF-PDGM-0466\", \"UCSF-PDGM-0141\", \"UCSF-PDGM-0005\",\n",
    "    \"UCSF-PDGM-0290\", \"UCSF-PDGM-0305\", \"UCSF-PDGM-0280\", \"UCSF-PDGM-0012\", \"UCSF-PDGM-0439\", \n",
    "    \"UCSF-PDGM-0195\", \"UCSF-PDGM-0433\", \"UCSF-PDGM-0332\", \"UCSF-PDGM-0415\", \"UCSF-PDGM-0007\",\n",
    "    \"UCSF-PDGM-0269\", \"UCSF-PDGM-0149\", \"UCSF-PDGM-0511\", \"UCSF-PDGM-0464\", \"UCSF-PDGM-0481\", \n",
    "    \"UCSF-PDGM-0111\", \"UCSF-PDGM-0295\", \"UCSF-PDGM-0010\", \"UCSF-PDGM-0377\", \"UCSF-PDGM-0058\",\n",
    "    \"UCSF-PDGM-0316\", \"UCSF-PDGM-0437\", \"UCSF-PDGM-0036\", \"UCSF-PDGM-0404\", \"UCSF-PDGM-0172\", \n",
    "    \"UCSF-PDGM-0401\", \"UCSF-PDGM-0085\", \"UCSF-PDGM-0201\", \"UCSF-PDGM-0122\", \"UCSF-PDGM-0035\",\n",
    "    \"UCSF-PDGM-0015\", \"UCSF-PDGM-0403\", \"UCSF-PDGM-0376\", \"UCSF-PDGM-0327\", \"UCSF-PDGM-0108\", \n",
    "    \"UCSF-PDGM-0394\", \"UCSF-PDGM-0414\", \"UCSF-PDGM-0163\", \"UCSF-PDGM-0391\", \"UCSF-PDGM-0235\"\n",
    "]\n",
    "Subjects_train = [\n",
    "    subj for subj in subjects if subj['subject_id'] in selected_subject_ids\n",
    "]\n",
    "SubjectsDataset_train = tio.SubjectsDataset(Subjects_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f62ea9b5-64af-401a-a03a-4cf83432a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing a manual check \n",
    "#for i, subject in enumerate(SubjectsDataset_train):\n",
    "#    print(f\"Subject {i} grade: {subject['grade']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a855fa-b041-43ef-aa19-d4927a36324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_subjects(batch):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for s in batch:\n",
    "        img = s['dti_fa'].data  # shape: (1, H, W, D)\n",
    "        img = img.permute(0, 3, 1, 2)  # shape: (1, D, H, W)\n",
    "        images.append(img)\n",
    "        labels.append(s['grade'])  # fix here\n",
    "    images = torch.stack(images)  # (B, 1, D, H, W)\n",
    "    labels = torch.tensor(labels)  # (B,)\n",
    "    return images, labels\n",
    "\n",
    "# DataLoader using the custom collate function\n",
    "train_loader = DataLoader(\n",
    "    SubjectsDataset_train, \n",
    "    batch_size=3, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_subjects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b94c6d3-8a8e-49c2-a5e8-47fe9677765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels.dtype)  # This will print torch.int64\n",
    "    break  # Just print for the first batch and stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2fb6e70-e220-4034-8a99-8adfce6548c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "os.chdir('/home/jovyan/git-gliograde/Deep_Learning')\n",
    "from resnet import generate_model\n",
    "\n",
    "model = generate_model(\n",
    "    model_depth=10,\n",
    "    n_classes=2,          # We are using a 2-class solution now \n",
    "    n_input_channels=1    # set to 1 for grayscale or 3 for RGB\n",
    ")\n",
    "\n",
    "#print(model)\n",
    "os.chdir('/home/jovyan/shared/data/PDGM/UCSF-PDGM-v5/UCSF-PDGM-v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "205a4cdb-9b3a-41bf-a6e4-56a03c404248",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) \n",
    "#Grade 0 weight: 397 / (2 × 79) = 397 / 158 = 2.531,\n",
    "#Grade 1 weight: 397 / (2 × 318) = 397 / 636 = 0.628\n",
    "class_weights = torch.FloatTensor([2.531, 0.628])  \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85fc82ef-85ad-4936-ad01-dad47ef2066e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dc8a7d7-4c8f-4683-8c3d-bce48519f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 66.2596\n",
      "Epoch 2, Loss: 61.8307\n",
      "Epoch 3, Loss: 64.0106\n",
      "Epoch 4, Loss: 63.5565\n",
      "Epoch 5, Loss: 61.1900\n",
      "Epoch 6, Loss: 61.3254\n",
      "Epoch 7, Loss: 63.9747\n",
      "Epoch 8, Loss: 57.7605\n",
      "Epoch 9, Loss: 59.7792\n",
      "Epoch 10, Loss: 55.1815\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "for epoch in range(10):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92114951-7478-4c5e-b246-88d7d9dac25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "FINAL EVALUATION\n",
      "==============================\n",
      "Training Accuracy: 187/397 = 0.471 (47.1%)\n"
     ]
    }
   ],
   "source": [
    "# Simple final evaluation\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate and display results\n",
    "correct = sum([pred == label for pred, label in zip(all_preds, all_labels)])\n",
    "total = len(all_labels)\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"Training Accuracy: {correct}/{total} = {accuracy:.3f} ({accuracy*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b84a9e-a584-41b0-b704-28291cb628ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for all subjects:\n",
      "==================================================\n",
      "Sample | True Grade | Predicted Grade\n",
      "--------------------------------------------------\n",
      "     1 |          1 |               0\n",
      "     2 |          1 |               1\n",
      "     3 |          1 |               0\n",
      "     4 |          1 |               0\n",
      "     5 |          1 |               1\n",
      "     6 |          1 |               1\n",
      "     7 |          1 |               1\n",
      "     8 |          1 |               1\n",
      "     9 |          1 |               0\n",
      "    10 |          0 |               0\n",
      "    11 |          1 |               0\n",
      "    12 |          1 |               1\n",
      "    13 |          0 |               1\n",
      "    14 |          1 |               1\n",
      "    15 |          1 |               0\n",
      "    16 |          1 |               0\n",
      "    17 |          1 |               0\n",
      "    18 |          1 |               1\n",
      "    19 |          1 |               0\n",
      "    20 |          1 |               0\n",
      "    21 |          1 |               1\n",
      "    22 |          1 |               1\n",
      "    23 |          1 |               1\n",
      "    24 |          1 |               0\n",
      "    25 |          1 |               1\n",
      "    26 |          1 |               1\n",
      "    27 |          1 |               1\n",
      "    28 |          0 |               1\n",
      "    29 |          0 |               0\n",
      "    30 |          1 |               0\n",
      "    31 |          1 |               0\n",
      "    32 |          1 |               0\n",
      "    33 |          1 |               0\n",
      "    34 |          1 |               0\n",
      "    35 |          1 |               1\n",
      "    36 |          0 |               0\n",
      "    37 |          0 |               0\n",
      "    38 |          0 |               0\n",
      "    39 |          1 |               1\n",
      "    40 |          1 |               1\n",
      "    41 |          1 |               0\n",
      "    42 |          1 |               0\n",
      "    43 |          0 |               0\n",
      "    44 |          1 |               1\n",
      "    45 |          0 |               0\n",
      "    46 |          0 |               0\n",
      "    47 |          1 |               0\n",
      "    48 |          1 |               0\n",
      "    49 |          1 |               0\n",
      "    50 |          1 |               0\n",
      "    51 |          1 |               0\n",
      "    52 |          1 |               0\n",
      "    53 |          1 |               1\n",
      "    54 |          1 |               0\n",
      "    55 |          1 |               0\n",
      "    56 |          1 |               0\n",
      "    57 |          1 |               0\n",
      "    58 |          0 |               0\n",
      "    59 |          0 |               0\n",
      "    60 |          1 |               0\n",
      "    61 |          1 |               0\n",
      "    62 |          0 |               0\n",
      "    63 |          1 |               1\n",
      "    64 |          1 |               0\n",
      "    65 |          1 |               0\n",
      "    66 |          1 |               1\n",
      "    67 |          1 |               0\n",
      "    68 |          0 |               0\n",
      "    69 |          1 |               1\n",
      "    70 |          1 |               1\n",
      "    71 |          0 |               1\n",
      "    72 |          1 |               0\n",
      "    73 |          0 |               0\n",
      "    74 |          1 |               1\n",
      "    75 |          1 |               0\n",
      "    76 |          1 |               0\n",
      "    77 |          1 |               1\n",
      "    78 |          1 |               0\n",
      "    79 |          1 |               0\n",
      "    80 |          1 |               1\n",
      "    81 |          0 |               1\n",
      "    82 |          1 |               0\n",
      "    83 |          1 |               1\n",
      "    84 |          1 |               0\n",
      "    85 |          1 |               1\n",
      "    86 |          0 |               0\n",
      "    87 |          1 |               0\n",
      "    88 |          1 |               0\n",
      "    89 |          1 |               1\n",
      "    90 |          1 |               0\n",
      "    91 |          1 |               0\n",
      "    92 |          1 |               0\n",
      "    93 |          0 |               0\n",
      "    94 |          1 |               1\n",
      "    95 |          1 |               0\n",
      "    96 |          1 |               1\n",
      "    97 |          1 |               0\n",
      "    98 |          1 |               1\n",
      "    99 |          1 |               1\n",
      "   100 |          1 |               1\n",
      "   101 |          1 |               1\n",
      "   102 |          1 |               0\n",
      "   103 |          1 |               1\n",
      "   104 |          0 |               0\n",
      "   105 |          1 |               0\n",
      "   106 |          1 |               1\n",
      "   107 |          1 |               1\n",
      "   108 |          1 |               1\n",
      "   109 |          1 |               1\n",
      "   110 |          1 |               1\n",
      "   111 |          1 |               1\n",
      "   112 |          1 |               1\n",
      "   113 |          1 |               1\n",
      "   114 |          1 |               0\n",
      "   115 |          1 |               0\n",
      "   116 |          1 |               0\n",
      "   117 |          0 |               0\n",
      "   118 |          0 |               0\n",
      "   119 |          1 |               0\n",
      "   120 |          0 |               0\n",
      "   121 |          1 |               1\n",
      "   122 |          1 |               1\n",
      "   123 |          0 |               0\n",
      "   124 |          1 |               0\n",
      "   125 |          1 |               0\n",
      "   126 |          1 |               1\n",
      "   127 |          1 |               0\n",
      "   128 |          1 |               1\n",
      "   129 |          1 |               0\n",
      "   130 |          1 |               0\n",
      "   131 |          0 |               0\n",
      "   132 |          1 |               0\n",
      "   133 |          1 |               0\n",
      "   134 |          1 |               0\n",
      "   135 |          0 |               0\n",
      "   136 |          1 |               0\n",
      "   137 |          1 |               1\n",
      "   138 |          1 |               0\n",
      "   139 |          1 |               0\n",
      "   140 |          1 |               0\n",
      "   141 |          1 |               0\n",
      "   142 |          1 |               0\n",
      "   143 |          1 |               1\n",
      "   144 |          1 |               0\n",
      "   145 |          1 |               1\n",
      "   146 |          0 |               0\n",
      "   147 |          0 |               0\n",
      "   148 |          1 |               0\n",
      "   149 |          1 |               1\n",
      "   150 |          1 |               0\n",
      "   151 |          1 |               1\n",
      "   152 |          1 |               0\n",
      "   153 |          1 |               0\n",
      "   154 |          1 |               0\n",
      "   155 |          1 |               0\n",
      "   156 |          1 |               0\n",
      "   157 |          1 |               1\n",
      "   158 |          1 |               1\n",
      "   159 |          1 |               1\n",
      "   160 |          1 |               0\n",
      "   161 |          1 |               0\n",
      "   162 |          1 |               0\n",
      "   163 |          1 |               0\n",
      "   164 |          1 |               0\n",
      "   165 |          1 |               0\n",
      "   166 |          1 |               0\n",
      "   167 |          1 |               1\n",
      "   168 |          1 |               0\n",
      "   169 |          1 |               0\n",
      "   170 |          1 |               0\n",
      "   171 |          1 |               1\n",
      "   172 |          1 |               0\n",
      "   173 |          1 |               0\n",
      "   174 |          0 |               0\n",
      "   175 |          1 |               0\n",
      "   176 |          1 |               0\n",
      "   177 |          1 |               0\n",
      "   178 |          1 |               0\n",
      "   179 |          1 |               0\n",
      "   180 |          1 |               0\n",
      "   181 |          0 |               0\n",
      "   182 |          0 |               0\n",
      "   183 |          1 |               0\n",
      "   184 |          1 |               0\n",
      "   185 |          0 |               0\n",
      "   186 |          1 |               0\n",
      "   187 |          1 |               0\n",
      "   188 |          1 |               1\n",
      "   189 |          1 |               0\n",
      "   190 |          1 |               0\n",
      "   191 |          1 |               0\n",
      "   192 |          1 |               1\n",
      "   193 |          1 |               0\n",
      "   194 |          0 |               0\n",
      "   195 |          1 |               0\n",
      "   196 |          1 |               0\n",
      "   197 |          1 |               0\n",
      "   198 |          1 |               0\n",
      "   199 |          1 |               1\n",
      "   200 |          1 |               1\n",
      "   201 |          1 |               0\n",
      "   202 |          1 |               1\n",
      "   203 |          1 |               1\n",
      "   204 |          1 |               1\n",
      "   205 |          1 |               1\n",
      "   206 |          1 |               1\n",
      "   207 |          0 |               0\n",
      "   208 |          0 |               0\n",
      "   209 |          1 |               0\n",
      "   210 |          1 |               1\n",
      "   211 |          1 |               0\n",
      "   212 |          1 |               0\n",
      "   213 |          0 |               0\n",
      "   214 |          1 |               1\n",
      "   215 |          1 |               0\n",
      "   216 |          1 |               0\n",
      "   217 |          1 |               0\n",
      "   218 |          0 |               1\n",
      "   219 |          1 |               0\n",
      "   220 |          1 |               0\n",
      "   221 |          0 |               0\n",
      "   222 |          1 |               0\n",
      "   223 |          1 |               0\n",
      "   224 |          1 |               1\n",
      "   225 |          1 |               0\n",
      "   226 |          1 |               1\n",
      "   227 |          0 |               0\n",
      "   228 |          1 |               1\n",
      "   229 |          1 |               0\n",
      "   230 |          0 |               0\n",
      "   231 |          0 |               0\n",
      "   232 |          1 |               1\n",
      "   233 |          1 |               1\n",
      "   234 |          1 |               0\n",
      "   235 |          0 |               0\n",
      "   236 |          1 |               1\n",
      "   237 |          0 |               1\n",
      "   238 |          1 |               1\n",
      "   239 |          1 |               0\n",
      "   240 |          1 |               0\n",
      "   241 |          1 |               0\n",
      "   242 |          1 |               0\n",
      "   243 |          1 |               0\n",
      "   244 |          0 |               0\n",
      "   245 |          1 |               0\n",
      "   246 |          1 |               1\n",
      "   247 |          0 |               1\n",
      "   248 |          0 |               0\n",
      "   249 |          0 |               0\n",
      "   250 |          1 |               0\n",
      "   251 |          1 |               0\n",
      "   252 |          1 |               0\n",
      "   253 |          0 |               0\n",
      "   254 |          1 |               0\n",
      "   255 |          0 |               0\n",
      "   256 |          1 |               0\n",
      "   257 |          1 |               0\n",
      "   258 |          1 |               0\n",
      "   259 |          1 |               1\n",
      "   260 |          1 |               1\n",
      "   261 |          1 |               1\n",
      "   262 |          0 |               0\n",
      "   263 |          1 |               1\n",
      "   264 |          1 |               0\n",
      "   265 |          1 |               0\n",
      "   266 |          1 |               0\n",
      "   267 |          1 |               0\n",
      "   268 |          1 |               0\n",
      "   269 |          0 |               0\n",
      "   270 |          0 |               0\n",
      "   271 |          1 |               0\n",
      "   272 |          1 |               1\n",
      "   273 |          0 |               0\n",
      "   274 |          1 |               1\n",
      "   275 |          1 |               0\n",
      "   276 |          1 |               0\n",
      "   277 |          1 |               0\n",
      "   278 |          1 |               1\n",
      "   279 |          0 |               0\n",
      "   280 |          1 |               0\n",
      "   281 |          1 |               0\n",
      "   282 |          0 |               0\n",
      "   283 |          1 |               1\n",
      "   284 |          1 |               0\n",
      "   285 |          1 |               0\n",
      "   286 |          1 |               0\n",
      "   287 |          0 |               0\n",
      "   288 |          0 |               0\n",
      "   289 |          1 |               1\n",
      "   290 |          1 |               0\n",
      "   291 |          1 |               0\n",
      "   292 |          1 |               0\n",
      "   293 |          1 |               0\n",
      "   294 |          1 |               1\n",
      "   295 |          1 |               1\n",
      "   296 |          1 |               0\n",
      "   297 |          1 |               0\n",
      "   298 |          0 |               0\n",
      "   299 |          1 |               0\n",
      "   300 |          1 |               0\n",
      "   301 |          0 |               0\n",
      "   302 |          1 |               1\n",
      "   303 |          1 |               0\n",
      "   304 |          1 |               1\n",
      "   305 |          0 |               0\n",
      "   306 |          1 |               1\n",
      "   307 |          1 |               0\n",
      "   308 |          1 |               0\n",
      "   309 |          1 |               0\n",
      "   310 |          1 |               0\n",
      "   311 |          1 |               1\n",
      "   312 |          1 |               0\n",
      "   313 |          1 |               0\n",
      "   314 |          1 |               0\n",
      "   315 |          1 |               1\n",
      "   316 |          1 |               1\n",
      "   317 |          0 |               0\n",
      "   318 |          0 |               0\n",
      "   319 |          1 |               0\n",
      "   320 |          0 |               0\n",
      "   321 |          1 |               1\n",
      "   322 |          1 |               0\n",
      "   323 |          1 |               1\n",
      "   324 |          1 |               0\n",
      "   325 |          1 |               0\n",
      "   326 |          0 |               1\n",
      "   327 |          1 |               0\n",
      "   328 |          1 |               0\n",
      "   329 |          1 |               0\n",
      "   330 |          1 |               1\n",
      "   331 |          1 |               0\n",
      "   332 |          1 |               0\n",
      "   333 |          1 |               0\n",
      "   334 |          1 |               1\n",
      "   335 |          1 |               0\n",
      "   336 |          0 |               0\n",
      "   337 |          1 |               0\n",
      "   338 |          0 |               0\n",
      "   339 |          1 |               0\n",
      "   340 |          1 |               1\n",
      "   341 |          0 |               1\n",
      "   342 |          1 |               0\n",
      "   343 |          1 |               0\n",
      "   344 |          1 |               1\n",
      "   345 |          1 |               0\n",
      "   346 |          1 |               0\n",
      "   347 |          0 |               0\n",
      "   348 |          0 |               0\n",
      "   349 |          1 |               0\n",
      "   350 |          1 |               0\n",
      "   351 |          1 |               1\n",
      "   352 |          1 |               1\n",
      "   353 |          1 |               0\n",
      "   354 |          0 |               0\n",
      "   355 |          0 |               0\n",
      "   356 |          1 |               1\n",
      "   357 |          1 |               0\n",
      "   358 |          0 |               0\n",
      "   359 |          0 |               0\n",
      "   360 |          0 |               0\n",
      "   361 |          1 |               0\n",
      "   362 |          1 |               0\n",
      "   363 |          1 |               0\n",
      "   364 |          0 |               0\n",
      "   365 |          0 |               0\n",
      "   366 |          1 |               0\n",
      "   367 |          1 |               0\n",
      "   368 |          1 |               0\n",
      "   369 |          1 |               0\n",
      "   370 |          1 |               0\n",
      "   371 |          1 |               1\n",
      "   372 |          1 |               1\n",
      "   373 |          1 |               0\n",
      "   374 |          0 |               0\n",
      "   375 |          1 |               1\n",
      "   376 |          1 |               1\n",
      "   377 |          1 |               0\n",
      "   378 |          1 |               1\n",
      "   379 |          1 |               1\n",
      "   380 |          1 |               1\n",
      "   381 |          1 |               0\n",
      "   382 |          1 |               1\n",
      "   383 |          1 |               0\n",
      "   384 |          1 |               1\n",
      "   385 |          1 |               0\n",
      "   386 |          1 |               0\n",
      "   387 |          1 |               1\n",
      "   388 |          1 |               0\n",
      "   389 |          1 |               1\n",
      "   390 |          0 |               0\n",
      "   391 |          1 |               1\n",
      "   392 |          1 |               1\n",
      "   393 |          1 |               0\n",
      "   394 |          0 |               0\n",
      "   395 |          1 |               0\n",
      "   396 |          1 |               1\n",
      "   397 |          1 |               0\n",
      "==================================================\n",
      "\n",
      "SUMMARY:\n",
      "Total samples: 397\n",
      "True labels used: [0, 1]\n",
      "Predicted labels: [0, 1]\n",
      "\n",
      "True label distribution:\n",
      "  Grade 0: 79 samples\n",
      "  Grade 1: 318 samples\n",
      "\n",
      "Predicted label distribution:\n",
      "  Grade 0: 271 samples\n",
      "  Grade 1: 126 samples\n",
      "\n",
      "✓ Model is predicting 2 different classes\n",
      "\n",
      "Accuracy: 187/397 = 0.471 (47.1%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions for all subjects:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Sample | True Grade | Predicted Grade\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "sample_count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            sample_count += 1\n",
    "            true_grade = labels[i].item()\n",
    "            pred_grade = predictions[i].item()\n",
    "            \n",
    "            print(f\"{sample_count:6d} | {true_grade:10d} | {pred_grade:15d}\")\n",
    "            \n",
    "            all_predictions.append(pred_grade)\n",
    "            all_labels.append(true_grade)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Summary\n",
    "unique_predictions = set(all_predictions)\n",
    "unique_labels = set(all_labels)\n",
    "\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"Total samples: {len(all_labels)}\")\n",
    "print(f\"True labels used: {sorted(unique_labels)}\")\n",
    "print(f\"Predicted labels: {sorted(unique_predictions)}\")\n",
    "\n",
    "# Count predictions\n",
    "from collections import Counter\n",
    "pred_counts = Counter(all_predictions)\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "print(f\"\\nTrue label distribution:\")\n",
    "for grade in sorted(label_counts.keys()):\n",
    "    print(f\"  Grade {grade}: {label_counts[grade]} samples\")\n",
    "\n",
    "print(f\"\\nPredicted label distribution:\")\n",
    "for grade in sorted(pred_counts.keys()):\n",
    "    print(f\"  Grade {grade}: {pred_counts[grade]} samples\")\n",
    "\n",
    "# Check if predicting only one class\n",
    "if len(unique_predictions) == 1:\n",
    "    print(f\"\\n🚨 WARNING: Model is predicting ONLY Grade {list(unique_predictions)[0]} for ALL samples!\")\n",
    "    print(\"This means the model hasn't learned to distinguish between classes.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Model is predicting {len(unique_predictions)} different classes\")\n",
    "\n",
    "# Accuracy\n",
    "correct = sum([p == l for p, l in zip(all_predictions, all_labels)])\n",
    "accuracy = correct / len(all_labels)\n",
    "print(f\"\\nAccuracy: {correct}/{len(all_labels)} = {accuracy:.3f} ({accuracy*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6ccfaa6-d110-481c-9d84-a058e1569798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "         Predicted\n",
      "         0    1\n",
      "Actual 0  70    9\n",
      "       1 201  117\n",
      "\n",
      "Accuracy: 187/397 = 0.471 (47.1%)\n"
     ]
    }
   ],
   "source": [
    "# Simple confusion matrix code\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get predictions from your model\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"         Predicted\")\n",
    "print(\"         0    1\")\n",
    "print(f\"Actual 0 {cm[0,0]:3d}  {cm[0,1]:3d}\")\n",
    "print(f\"       1 {cm[1,0]:3d}  {cm[1,1]:3d}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "total = len(all_labels)\n",
    "correct = cm[0,0] + cm[1,1]\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"\\nAccuracy: {correct}/{total} = {accuracy:.3f} ({accuracy*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
