{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"9361368b-b72d-4e12-b8b4-0c3bf2abf8aa","cell_type":"code","source":"#!/usr/bin/env python\n\"\"\"\nEnhanced Binary Tumor Grade Classifier with Robust Validation\nClassifies gliomas as High Grade (4) vs Low Grade (2&3)\n\"\"\"\n\n# ============= COMPLETE IMPORTS =============\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport joblib\nfrom datetime import datetime\n\nfrom sklearn.model_selection import (\n    train_test_split, cross_val_score, StratifiedKFold, \n    GridSearchCV, cross_validate\n)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.feature_selection import SelectKBest, f_classif, RFECV\nfrom sklearn.calibration import CalibratedClassifierCV, calibration_curve\nfrom sklearn.utils import resample\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, roc_auc_score,\n    roc_curve, accuracy_score, balanced_accuracy_score,\n    precision_recall_curve, average_precision_score,\n    f1_score, precision_score, recall_score, make_scorer\n)\n\nwarnings.filterwarnings('ignore')\nprint(\"âœ“ All libraries imported successfully!\")\n\n# ============= CLINICAL FEATURE ENHANCEMENT FUNCTION =============\ndef enhance_clinical_features(df):\n    \"\"\"\n    Create more informative clinical features based on domain knowledge\n    This function should be called BEFORE one-hot encoding\n    \"\"\"\n    print(\"\\nEnhancing clinical features...\")\n    \n    # 1. Create molecular subtype based on WHO 2021 classification\n    def get_molecular_class(row):\n        idh = str(row.get('idh_status', row.get('IDH', 'unknown'))).lower()\n        p19q = str(row.get('1p19q', row.get('1p/19q', 'unknown'))).lower()\n        \n        if 'wildtype' in idh:\n            return 'glioblastoma_IDHwt'\n        elif 'co-deletion' in p19q and 'wildtype' not in idh:\n            return 'oligodendroglioma_IDHmut_1p19q'\n        elif idh not in ['unknown', 'missing', 'nan', ''] and 'wildtype' not in idh:\n            return 'astrocytoma_IDHmut'\n        else:\n            return 'molecular_unknown'\n    \n    df['molecular_class'] = df.apply(get_molecular_class, axis=1)\n    \n    # 2. Age categories (clinically meaningful cutoffs)\n    age_col = 'age_at_mri' if 'age_at_mri' in df.columns else 'Age at MRI'\n    if age_col in df.columns:\n        df['age_pediatric'] = (df[age_col] < 18).astype(int)\n        df['age_young_adult'] = ((df[age_col] >= 18) & (df[age_col] < 40)).astype(int)\n        df['age_middle'] = ((df[age_col] >= 40) & (df[age_col] < 55)).astype(int)\n        df['age_older'] = ((df[age_col] >= 55) & (df[age_col] < 65)).astype(int)\n        df['age_elderly'] = (df[age_col] >= 65).astype(int)\n        \n        # Age as risk factor (continuous)\n        df['age_risk_score'] = df[age_col] / 100  # Normalize to 0-1 range\n    \n    # 3. Process MGMT index as ordinal (if available)\n    mgmt_idx_col = 'mgmt_index' if 'mgmt_index' in df.columns else 'MGMT index'\n    if mgmt_idx_col in df.columns:\n        df['mgmt_index_numeric'] = pd.to_numeric(df[mgmt_idx_col], errors='coerce')\n        df['mgmt_methylated_high'] = (df['mgmt_index_numeric'] > 10).astype(int)\n        df['mgmt_methylated_low'] = ((df['mgmt_index_numeric'] > 0) & (df['mgmt_index_numeric'] <= 10)).astype(int)\n        df['mgmt_unmethylated'] = (df['mgmt_index_numeric'] == 0).astype(int)\n    \n    # 4. IDH mutation binary (simplified)\n    idh_col = 'idh_status' if 'idh_status' in df.columns else 'IDH'\n    if idh_col in df.columns:\n        df['idh_wildtype'] = df[idh_col].str.contains('wildtype', case=False, na=False).astype(int)\n        df['idh_mutant'] = (~df[idh_col].str.contains('wildtype', case=False, na=False) & \n                           df[idh_col].notna() & \n                           (df[idh_col] != 'unknown')).astype(int)\n    \n    # 5. 1p19q co-deletion binary\n    p19q_col = '1p19q' if '1p19q' in df.columns else '1p/19q'\n    if p19q_col in df.columns:\n        df['has_1p19q_codeletion'] = df[p19q_col].str.contains('co-deletion', case=False, na=False).astype(int)\n        df['p19q_intact'] = df[p19q_col].str.contains('intact', case=False, na=False).astype(int)\n    \n    # 6. Combined molecular risk score\n    df['molecular_risk_score'] = 0\n    if 'idh_wildtype' in df.columns:\n        df['molecular_risk_score'] += df['idh_wildtype'] * 3  # Strongest predictor of Grade 4\n    if 'has_1p19q_codeletion' in df.columns:\n        df['molecular_risk_score'] -= df['has_1p19q_codeletion'] * 2  # Predicts lower grade\n    \n    mgmt_col = 'mgmt_status' if 'mgmt_status' in df.columns else 'MGMT status'\n    if mgmt_col in df.columns:\n        df['molecular_risk_score'] += (df[mgmt_col] == 'negative').astype(int)\n        df['molecular_risk_score'] -= (df[mgmt_col] == 'positive').astype(int)\n    \n    # 7. Extent of resection score\n    eor_col = 'eor' if 'eor' in df.columns else 'EOR'\n    if eor_col in df.columns:\n        eor_map = {'GTR': 3, 'STR': 2, 'biopsy': 1}\n        df['eor_score'] = df[eor_col].map(eor_map).fillna(0)\n    \n    # 8. Create interaction features\n    if 'age_risk_score' in df.columns and 'idh_wildtype' in df.columns:\n        df['age_idh_interaction'] = df['age_risk_score'] * df['idh_wildtype']\n    \n    # 9. Favorable vs unfavorable profile\n    df['favorable_profile'] = 0\n    if 'idh_mutant' in df.columns:\n        df['favorable_profile'] += df['idh_mutant']\n    if 'has_1p19q_codeletion' in df.columns:\n        df['favorable_profile'] += df['has_1p19q_codeletion']\n    if mgmt_col in df.columns:\n        df['favorable_profile'] += (df[mgmt_col] == 'positive').astype(int)\n    if age_col in df.columns:\n        df['favorable_profile'] += (df[age_col] < 50).astype(int)\n    \n    print(f\"  Added {sum([1 for col in df.columns if col not in ['molecular_class']])} new clinical features\")\n    print(f\"  Molecular classes: {df['molecular_class'].value_counts().to_dict()}\")\n    \n    return df\n\n# ============= BOOTSTRAP FEATURE IMPORTANCE =============\ndef bootstrap_feature_importance(X, y, model_class, model_params, n_bootstrap=50, random_state=42):\n    \"\"\"\n    Calculate bootstrap confidence intervals for feature importance\n    \"\"\"\n    print(f\"\\nCalculating bootstrap feature importance ({n_bootstrap} iterations)...\")\n    \n    np.random.seed(random_state)\n    importances_list = []\n    \n    for i in range(n_bootstrap):\n        # Bootstrap sample\n        X_boot, y_boot = resample(X, y, random_state=i)\n        \n        # Fit model\n        model = model_class(**model_params)\n        model.fit(X_boot, y_boot)\n        \n        # Store importances\n        importances_list.append(model.feature_importances_)\n        \n        if (i + 1) % 10 == 0:\n            print(f\"  Completed {i + 1}/{n_bootstrap} bootstrap samples\")\n    \n    # Calculate statistics\n    importances_array = np.array(importances_list)\n    importance_mean = np.mean(importances_array, axis=0)\n    importance_std = np.std(importances_array, axis=0)\n    importance_ci_lower = np.percentile(importances_array, 2.5, axis=0)\n    importance_ci_upper = np.percentile(importances_array, 97.5, axis=0)\n    \n    return {\n        'mean': importance_mean,\n        'std': importance_std,\n        'ci_lower': importance_ci_lower,\n        'ci_upper': importance_ci_upper\n    }\n\n# ============= ENHANCED EVALUATION FUNCTION =============\ndef evaluate_model_comprehensive(model, X_test, y_test, model_name=\"Model\"):\n    \"\"\"\n    Comprehensive model evaluation with multiple metrics\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"{model_name.upper()} EVALUATION\")\n    print(f\"{'='*60}\")\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)[:, 1]\n    \n    # Classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred, \n                              target_names=['Low Grade (2&3)', 'High Grade (4)'],\n                              digits=3))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    print(f\"\\nConfusion Matrix:\")\n    print(f\"                Predicted\")\n    print(f\"Actual    Low   High\")\n    print(f\"Low      {cm[0,0]:4d}  {cm[0,1]:4d}\")\n    print(f\"High     {cm[1,0]:4d}  {cm[1,1]:4d}\")\n    \n    # Metrics\n    metrics = {\n        'accuracy': accuracy_score(y_test, y_pred),\n        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n        'roc_auc': roc_auc_score(y_test, y_pred_proba),\n        'f1_score': f1_score(y_test, y_pred),\n        'precision': precision_score(y_test, y_pred),\n        'recall': recall_score(y_test, y_pred),\n        'avg_precision': average_precision_score(y_test, y_pred_proba)\n    }\n    \n    print(f\"\\nDetailed Metrics:\")\n    for metric, value in metrics.items():\n        print(f\"  {metric:20s}: {value:.3f}\")\n    \n    return metrics, y_pred, y_pred_proba\n\n# ============= MAIN EXECUTION =============\nprint(\"\\n\" + \"=\"*60)\nprint(\"ENHANCED BINARY TUMOR GRADE CLASSIFIER\")\nprint(\"High Grade (4) vs Low Grade (2&3)\")\nprint(\"=\"*60)\n\n# Load your original data\ndf = pd.read_csv('patient_level_comprehensive_features_fixed.csv')\nprint(f\"\\nInitial data shape: {df.shape}\")\n\n# ============= DROP SHELL FEATURES =============\nshell_features_to_drop = [\n    'patient_id', 'shell_0_fa_mean', 'shell_0_fa_std', 'shell_0_fa_median', 'shell_0_voxel_count',\n    'shell_1_fa_mean', 'shell_1_fa_std', 'shell_1_fa_median', 'shell_1_voxel_count',\n    'shell_2_fa_mean', 'shell_2_fa_std', 'shell_2_fa_median', 'shell_2_voxel_count',\n    'shell_3_fa_mean', 'shell_3_fa_std', 'shell_3_fa_median', 'shell_3_voxel_count',\n    'shell_0_gradient_mean', 'shell_0_gradient_std', 'shell_1_gradient_mean',\n    'shell_1_gradient_std', 'shell_2_gradient_mean', 'shell_2_gradient_std',\n    'shell_3_gradient_mean', 'shell_3_gradient_std'\n]\n\ncols_to_drop = [col for col in shell_features_to_drop if col in df.columns]\ndf = df.drop(columns=cols_to_drop)\nprint(f\"Shape after dropping shell features: {df.shape}\")\n\n# ============= CREATE BINARY TARGET =============\ndf['grade_binary'] = (df['who_grade'] == 4).astype(int)\n\nprint(f\"\\nOriginal grade distribution:\")\nprint(df['who_grade'].value_counts().sort_index())\nprint(f\"\\nBinary grade distribution:\")\nprint(f\"High Grade (1): {(df['grade_binary']==1).sum()} samples ({(df['grade_binary']==1).mean():.1%})\")\nprint(f\"Low Grade (0): {(df['grade_binary']==0).sum()} samples ({(df['grade_binary']==0).mean():.1%})\")\n\n# ============= ENHANCE CLINICAL FEATURES =============\ndf = enhance_clinical_features(df)\n\n# ============= HANDLE REMAINING CATEGORICAL FEATURES =============\ncategorical_cols = ['sex', 'mgmt_status', 'mgmt_index', '1p19q', 'idh_status', 'eor', 'molecular_class']\nexisting_cat_cols = [col for col in categorical_cols if col in df.columns]\nprint(f\"\\nCategorical columns to encode: {existing_cat_cols}\")\n\n# Handle missing values and encode\ndf_processed = df.copy()\nfor col in existing_cat_cols:\n    df_processed[col] = df_processed[col].fillna('missing')\n    df_processed[col] = df_processed[col].replace('unknown', 'missing')\n\nif existing_cat_cols:\n    df_processed = pd.get_dummies(df_processed, columns=existing_cat_cols, drop_first=False)\n\n# Handle missing values in numerical features\nnumerical_cols = df_processed.select_dtypes(include=[np.number]).columns\nnumerical_cols = numerical_cols.drop(['who_grade', 'grade_binary'])\n\nimputer = SimpleImputer(strategy='median')\ndf_processed[numerical_cols] = imputer.fit_transform(df_processed[numerical_cols])\n\nprint(f\"\\nFinal processed data shape: {df_processed.shape}\")\n\n# ============= IDENTIFY CLINICAL VS IMAGING FEATURES =============\nclinical_keywords = ['age', 'sex', 'mgmt', 'idh', '1p19q', 'eor', 'molecular', 'favorable', \n                    'risk_score', 'methylated', 'wildtype', 'mutant', 'codeletion', 'intact']\nimaging_keywords = ['fa_', 'boundary', 'core', 'enhancing', 'edema', 'gradient', 'voxel']\n\nall_features = [col for col in df_processed.columns if col not in ['who_grade', 'grade_binary']]\nclinical_features = [f for f in all_features if any(k in f.lower() for k in clinical_keywords)]\nimaging_features = [f for f in all_features if any(k in f.lower() for k in imaging_keywords)]\nother_features = [f for f in all_features if f not in clinical_features and f not in imaging_features]\n\nprint(f\"\\nFeature breakdown:\")\nprint(f\"  Clinical features: {len(clinical_features)}\")\nprint(f\"  Imaging features: {len(imaging_features)}\")\nprint(f\"  Other features: {len(other_features)}\")\n\n# ============= PREPARE FEATURES AND TARGET =============\nX = df_processed.drop(columns=['who_grade', 'grade_binary'])\ny = df_processed['grade_binary']\n\nprint(f\"\\nFeatures shape: {X.shape}\")\nprint(f\"Target shape: {y.shape}\")\n\n# ============= TRAIN-TEST SPLIT =============\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\n\nprint(f\"\\nTrain/Test split:\")\nprint(f\"  Train: {X_train.shape}, High Grade: {y_train.mean():.1%}\")\nprint(f\"  Test: {X_test.shape}, High Grade: {y_test.mean():.1%}\")\n\n# ============= FEATURE SCALING =============\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# ============= FEATURE SELECTION (NEW!) =============\nprint(\"\\n\" + \"=\"*60)\nprint(\"FEATURE SELECTION\")\nprint(\"=\"*60)\n\n# Calculate class weights\nclasses = np.unique(y_train)\nweights = compute_class_weight('balanced', classes=classes, y=y_train)\nclass_weight_dict = dict(zip(classes, weights))\nprint(f\"\\nClass weights: {class_weight_dict}\")\n\n# Feature selection using SelectKBest\nprint(\"\\nPerforming feature selection...\")\nselector = SelectKBest(f_classif, k=min(50, X_train_scaled.shape[1]))\nX_train_selected = selector.fit_transform(X_train_scaled, y_train)\nX_test_selected = selector.transform(X_test_scaled)\n\nselected_features = X.columns[selector.get_support()]\nprint(f\"Selected {len(selected_features)} features from {X_train_scaled.shape[1]} original features\")\n\n# ============= HYPERPARAMETER OPTIMIZATION (NEW!) =============\nprint(\"\\n\" + \"=\"*60)\nprint(\"HYPERPARAMETER OPTIMIZATION\")\nprint(\"=\"*60)\n\n# Define parameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [15, 20, 25],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2']\n}\n\nprint(f\"Parameter grid size: {np.prod([len(v) for v in param_grid.values()])} combinations\")\n\n# Grid search with cross-validation\nrf_base = RandomForestClassifier(\n    class_weight=class_weight_dict,\n    random_state=42,\n    n_jobs=-1\n)\n\ngrid_search = GridSearchCV(\n    rf_base,\n    param_grid,\n    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n    scoring='balanced_accuracy',\n    n_jobs=-1,\n    verbose=1\n)\n\nprint(\"\\nPerforming grid search...\")\ngrid_search.fit(X_train_selected, y_train)\n\nprint(f\"\\nBest parameters: {grid_search.best_params_}\")\nprint(f\"Best cross-validation score: {grid_search.best_score_:.3f}\")\n\n# Get best model\nbest_rf = grid_search.best_estimator_\n\n# ============= CROSS-VALIDATION ASSESSMENT (NEW!) =============\nprint(\"\\n\" + \"=\"*60)\nprint(\"CROSS-VALIDATION ASSESSMENT\")\nprint(\"=\"*60)\n\n# Define scoring metrics\nscoring = {\n    'accuracy': 'accuracy',\n    'balanced_accuracy': 'balanced_accuracy',\n    'roc_auc': 'roc_auc',\n    'f1': 'f1',\n    'precision': 'precision',\n    'recall': 'recall'\n}\n\nprint(\"Performing comprehensive cross-validation...\")\ncv_results = cross_validate(\n    best_rf,\n    X_train_selected,\n    y_train,\n    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n    scoring=scoring,\n    return_train_score=True,\n    n_jobs=-1\n)\n\nprint(\"\\nCross-Validation Results (5-fold):\")\nprint(\"-\" * 50)\nfor metric in scoring.keys():\n    train_scores = cv_results[f'train_{metric}']\n    test_scores = cv_results[f'test_{metric}']\n    print(f\"{metric:20s}: {test_scores.mean():.3f} Â± {test_scores.std():.3f} \"\n          f\"(train: {train_scores.mean():.3f})\")\n\n# ============= MODEL TRAINING ON FULL TRAINING SET =============\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL MODEL TRAINING\")\nprint(\"=\"*60)\n\nprint(\"Training final model on full training set...\")\nbest_rf.fit(X_train_selected, y_train)\n\n# ============= COMPREHENSIVE MODEL EVALUATION =============\nfinal_metrics, y_pred, y_pred_proba = evaluate_model_comprehensive(\n    best_rf, X_test_selected, y_test, \"Final Optimized Model\"\n)\n\n# ============= BOOTSTRAP FEATURE IMPORTANCE (NEW!) =============\nprint(\"\\n\" + \"=\"*60)\nprint(\"BOOTSTRAP FEATURE IMPORTANCE ANALYSIS\")\nprint(\"=\"*60)\n\n# Get bootstrap feature importance\nbootstrap_importance = bootstrap_feature_importance(\n    X_train_selected, y_train,\n    RandomForestClassifier,\n    best_rf.get_params(),\n    n_bootstrap=50,\n    random_state=42\n)\n\n# Create comprehensive feature importance DataFrame\nfeature_importance_df = pd.DataFrame({\n    'feature': selected_features,\n    'importance_mean': bootstrap_importance['mean'],\n    'importance_std': bootstrap_importance['std'],\n    'importance_ci_lower': bootstrap_importance['ci_lower'],\n    'importance_ci_upper': bootstrap_importance['ci_upper'],\n    'category': ['clinical' if any(k in f.lower() for k in clinical_keywords) \n                 else 'imaging' if any(k in f.lower() for k in imaging_keywords)\n                 else 'other' for f in selected_features]\n}).sort_values('importance_mean', ascending=False)\n\n# Display top features with confidence intervals\nprint(\"\\nTop 15 Features (with 95% confidence intervals):\")\nprint(\"-\" * 80)\nfor idx, row in feature_importance_df.head(15).iterrows():\n    ci_width = row['importance_ci_upper'] - row['importance_ci_lower']\n    print(f\"{row['feature']:35s}: {row['importance_mean']:.4f} \"\n          f\"[{row['importance_ci_lower']:.4f}, {row['importance_ci_upper']:.4f}] \"\n          f\"({row['category']})\")\n\n# Category importance with confidence\nclinical_importance = feature_importance_df[feature_importance_df['category'] == 'clinical']['importance_mean'].sum()\nimaging_importance = feature_importance_df[feature_importance_df['category'] == 'imaging']['importance_mean'].sum()\ntotal_importance = clinical_importance + imaging_importance\n\nprint(f\"\\nOverall Feature Category Importance:\")\nprint(f\"  Clinical: {clinical_importance:.3f} ({clinical_importance/total_importance:.1%})\")\nprint(f\"  Imaging: {imaging_importance:.3f} ({imaging_importance/total_importance:.1%})\")\n\n# ============= MODEL CALIBRATION ASSESSMENT (NEW!) =============\nprint(\"\\n\" + \"=\"*60)\nprint(\"MODEL CALIBRATION ASSESSMENT\")\nprint(\"=\"*60)\n\n# Calibrate probabilities\ncalibrated_model = CalibratedClassifierCV(best_rf, method='isotonic', cv=3)\ncalibrated_model.fit(X_train_selected, y_train)\n\n# Get calibrated predictions\ny_pred_cal_proba = calibrated_model.predict_proba(X_test_selected)[:, 1]\n\n# Calibration assessment\nfraction_pos, mean_pred_value = calibration_curve(y_test, y_pred_proba, n_bins=10)\nfraction_pos_cal, mean_pred_value_cal = calibration_curve(y_test, y_pred_cal_proba, n_bins=10)\n\nprint(\"Calibration Assessment:\")\nprint(f\"  Original model reliability: Mean absolute difference = \"\n      f\"{np.mean(np.abs(fraction_pos - mean_pred_value)):.3f}\")\nprint(f\"  Calibrated model reliability: Mean absolute difference = \"\n      f\"{np.mean(np.abs(fraction_pos_cal - mean_pred_value_cal)):.3f}\")\n\n# ============= CLINICAL-ONLY MODEL COMPARISON (ENHANCED) =============\nprint(\"\\n\" + \"=\"*60)\nprint(\"CLINICAL-ONLY MODEL COMPARISON\")\nprint(\"=\"*60)\n\n# Select only clinical features from selected features\nclinical_selected = [f for f in selected_features if f in clinical_features]\nclinical_indices = [i for i, f in enumerate(selected_features) if f in clinical_selected]\n\nif len(clinical_selected) > 0:\n    X_train_clinical = X_train_selected[:, clinical_indices]\n    X_test_clinical = X_test_selected[:, clinical_indices]\n    \n    print(f\"Using {len(clinical_selected)} clinical features\")\n    \n    # Train clinical-only model with same hyperparameters\n    rf_clinical = RandomForestClassifier(**best_rf.get_params())\n    rf_clinical.fit(X_train_clinical, y_train)\n    \n    # Evaluate clinical-only model\n    clinical_metrics, _, _ = evaluate_model_comprehensive(\n        rf_clinical, X_test_clinical, y_test, \"Clinical-Only Model\"\n    )\n    \n    print(f\"\\nModel Comparison:\")\n    print(\"-\" * 40)\n    for metric in ['accuracy', 'balanced_accuracy', 'roc_auc', 'f1_score']:\n        improvement = final_metrics[metric] - clinical_metrics[metric]\n        print(f\"{metric:20s}: Full {final_metrics[metric]:.3f} vs Clinical {clinical_metrics[metric]:.3f} \"\n              f\"(+{improvement:+.3f})\")\n\n# ============= SAVE ENHANCED RESULTS =============\nprint(\"\\n\" + \"=\"*60)\nprint(\"SAVING ENHANCED RESULTS\")\nprint(\"=\"*60)\n\n# Create results dictionary\nresults = {\n    'timestamp': datetime.now().isoformat(),\n    'model_type': 'RandomForestClassifier',\n    'best_params': best_rf.get_params(),\n    'cv_results': {metric: {'mean': cv_results[f'test_{metric}'].mean(), \n                           'std': cv_results[f'test_{metric}'].std()} \n                  for metric in scoring.keys()},\n    'test_metrics': final_metrics,\n    'selected_features': selected_features.tolist(),\n    'feature_importance': feature_importance_df.to_dict('records')\n}\n\n# Save models and results\njoblib.dump(best_rf, 'enhanced_binary_classifier_optimized.pkl')\njoblib.dump(calibrated_model, 'enhanced_binary_classifier_calibrated.pkl')\njoblib.dump(scaler, 'enhanced_binary_scaler_optimized.pkl')\njoblib.dump(selector, 'enhanced_feature_selector.pkl')\nfeature_importance_df.to_csv('enhanced_feature_importance_with_ci.csv', index=False)\n\n# Save results summary\nimport json\n\ndef convert_numpy_types(obj):\n    \"\"\"Convert numpy types to native Python types for JSON serialization\"\"\"\n    if isinstance(obj, np.integer):\n        return int(obj)\n    elif isinstance(obj, np.floating):\n        return float(obj)\n    elif isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, dict):\n        return {str(key): convert_numpy_types(value) for key, value in obj.items()}\n    elif isinstance(obj, list):\n        return [convert_numpy_types(item) for item in obj]\n    else:\n        return obj\n\n# Convert results to JSON-serializable format\nresults_serializable = convert_numpy_types(results)\n\nwith open('model_results_summary.json', 'w') as f:\n    json.dump(results_serializable, f, indent=2)\n\nprint(\"âœ“ Optimized model saved as 'enhanced_binary_classifier_optimized.pkl'\")\nprint(\"âœ“ Calibrated model saved as 'enhanced_binary_classifier_calibrated.pkl'\")\nprint(\"âœ“ Feature selector saved as 'enhanced_feature_selector.pkl'\")\nprint(\"âœ“ Feature importance with CI saved as 'enhanced_feature_importance_with_ci.csv'\")\nprint(\"âœ“ Results summary saved as 'model_results_summary.json'\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ENHANCED ANALYSIS COMPLETE!\")\nprint(\"=\"*60)\nprint(f\"Final model performance:\")\nprint(f\"  Cross-validation balanced accuracy: {cv_results['test_balanced_accuracy'].mean():.3f} Â± {cv_results['test_balanced_accuracy'].std():.3f}\")\nprint(f\"  Test set balanced accuracy: {final_metrics['balanced_accuracy']:.3f}\")\nprint(f\"  Test set ROC-AUC: {final_metrics['roc_auc']:.3f}\")\nprint(f\"  Features used: {len(selected_features)} of {X.shape[1]} original features\")\nprint(\"=\"*60)","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"âœ“ All libraries imported successfully!\n\n============================================================\nENHANCED BINARY TUMOR GRADE CLASSIFIER\nHigh Grade (4) vs Low Grade (2&3)\n============================================================\n\nInitial data shape: (500, 91)\nShape after dropping shell features: (500, 66)\n\nOriginal grade distribution:\nwho_grade\n2     56\n3     43\n4    401\nName: count, dtype: int64\n\nBinary grade distribution:\nHigh Grade (1): 401 samples (80.2%)\nLow Grade (0): 99 samples (19.8%)\n\nEnhancing clinical features...\n  Added 85 new clinical features\n  Molecular classes: {'glioblastoma_IDHwt': 397, 'astrocytoma_IDHmut': 88, 'oligodendroglioma_IDHmut_1p19q': 15}\n\nCategorical columns to encode: ['sex', 'mgmt_status', 'mgmt_index', '1p19q', 'idh_status', 'eor', 'molecular_class']\n\nFinal processed data shape: (500, 124)\n\nFeature breakdown:\n  Clinical features: 64\n  Imaging features: 50\n  Other features: 11\n\nFeatures shape: (500, 122)\nTarget shape: (500,)\n\nTrain/Test split:\n  Train: (400, 122), High Grade: 80.2%\n  Test: (100, 122), High Grade: 80.0%\n\n============================================================\nFEATURE SELECTION\n============================================================\n\nClass weights: {0: 2.5316455696202533, 1: 0.6230529595015576}\n\nPerforming feature selection...\nSelected 50 features from 122 original features\n\n============================================================\nHYPERPARAMETER OPTIMIZATION\n============================================================\nParameter grid size: 162 combinations\n\nPerforming grid search...\nFitting 5 folds for each of 162 candidates, totalling 810 fits\n\nBest parameters: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\nBest cross-validation score: 0.862\n\n============================================================\nCROSS-VALIDATION ASSESSMENT\n============================================================\nPerforming comprehensive cross-validation...\n\nCross-Validation Results (5-fold):\n--------------------------------------------------\naccuracy            : 0.915 Â± 0.020 (train: 0.969)\nbalanced_accuracy   : 0.862 Â± 0.054 (train: 0.958)\nroc_auc             : 0.953 Â± 0.025 (train: 0.996)\nf1                  : 0.947 Â± 0.012 (train: 0.980)\nprecision           : 0.945 Â± 0.027 (train: 0.985)\nrecall              : 0.950 Â± 0.012 (train: 0.976)\n\n============================================================\nFINAL MODEL TRAINING\n============================================================\nTraining final model on full training set...\n\n============================================================\nFINAL OPTIMIZED MODEL EVALUATION\n============================================================\n\nClassification Report:\n                 precision    recall  f1-score   support\n\nLow Grade (2&3)      0.737     0.700     0.718        20\n High Grade (4)      0.926     0.938     0.932        80\n\n       accuracy                          0.890       100\n      macro avg      0.831     0.819     0.825       100\n   weighted avg      0.888     0.890     0.889       100\n\n\nConfusion Matrix:\n                Predicted\nActual    Low   High\nLow        14     6\nHigh        5    75\n\nDetailed Metrics:\n  accuracy            : 0.890\n  balanced_accuracy   : 0.819\n  roc_auc             : 0.912\n  f1_score            : 0.932\n  precision           : 0.926\n  recall              : 0.938\n  avg_precision       : 0.974\n\n============================================================\nBOOTSTRAP FEATURE IMPORTANCE ANALYSIS\n============================================================\n\nCalculating bootstrap feature importance (50 iterations)...\n  Completed 10/50 bootstrap samples\n  Completed 20/50 bootstrap samples\n  Completed 30/50 bootstrap samples\n  Completed 40/50 bootstrap samples\n  Completed 50/50 bootstrap samples\n\nTop 15 Features (with 95% confidence intervals):\n--------------------------------------------------------------------------------\nmolecular_risk_score               : 0.0849 [0.0645, 0.1054] (clinical)\nmolecular_class_glioblastoma_IDHwt : 0.0814 [0.0617, 0.1053] (clinical)\nidh_status_wildtype                : 0.0747 [0.0584, 0.0958] (clinical)\nage_idh_interaction                : 0.0515 [0.0339, 0.0701] (clinical)\nidh_wildtype                       : 0.0479 [0.0344, 0.0645] (clinical)\nidh_mutant                         : 0.0349 [0.0210, 0.0478] (clinical)\nboundary_shell_0_voxel_count       : 0.0347 [0.0185, 0.0508] (imaging)\nmgmt_status_missing                : 0.0329 [0.0124, 0.0610] (clinical)\nmolecular_class_astrocytoma_IDHmut : 0.0317 [0.0121, 0.0476] (clinical)\ntumor_brain_ratio                  : 0.0284 [0.0140, 0.0429] (other)\nboundary_shell_1_voxel_count       : 0.0281 [0.0140, 0.0481] (imaging)\ntumor_volume                       : 0.0277 [0.0109, 0.0417] (other)\nmgmt_index_missing                 : 0.0276 [0.0103, 0.0545] (clinical)\nfavorable_profile                  : 0.0243 [0.0114, 0.0393] (clinical)\neor_score                          : 0.0208 [0.0083, 0.0349] (clinical)\n\nOverall Feature Category Importance:\n  Clinical: 0.612 (67.2%)\n  Imaging: 0.299 (32.8%)\n\n============================================================\nMODEL CALIBRATION ASSESSMENT\n============================================================\nCalibration Assessment:\n  Original model reliability: Mean absolute difference = 0.214\n  Calibrated model reliability: Mean absolute difference = 0.265\n\n============================================================\nCLINICAL-ONLY MODEL COMPARISON\n============================================================\nUsing 25 clinical features\n\n============================================================\nCLINICAL-ONLY MODEL EVALUATION\n============================================================\n\nClassification Report:\n                 precision    recall  f1-score   support\n\nLow Grade (2&3)      0.650     0.650     0.650        20\n High Grade (4)      0.912     0.912     0.912        80\n\n       accuracy                          0.860       100\n      macro avg      0.781     0.781     0.781       100\n   weighted avg      0.860     0.860     0.860       100\n\n\nConfusion Matrix:\n                Predicted\nActual    Low   High\nLow        13     7\nHigh        7    73\n\nDetailed Metrics:\n  accuracy            : 0.860\n  balanced_accuracy   : 0.781\n  roc_auc             : 0.912\n  f1_score            : 0.912\n  precision           : 0.912\n  recall              : 0.912\n  avg_precision       : 0.974\n\nModel Comparison:\n----------------------------------------\naccuracy            : Full 0.890 vs Clinical 0.860 (++0.030)\nbalanced_accuracy   : Full 0.819 vs Clinical 0.781 (++0.037)\nroc_auc             : Full 0.912 vs Clinical 0.912 (++0.000)\nf1_score            : Full 0.932 vs Clinical 0.912 (++0.019)\n\n============================================================\nSAVING ENHANCED RESULTS\n============================================================\nâœ“ Optimized model saved as 'enhanced_binary_classifier_optimized.pkl'\nâœ“ Calibrated model saved as 'enhanced_binary_classifier_calibrated.pkl'\nâœ“ Feature selector saved as 'enhanced_feature_selector.pkl'\nâœ“ Feature importance with CI saved as 'enhanced_feature_importance_with_ci.csv'\nâœ“ Results summary saved as 'model_results_summary.json'\n\n============================================================\nENHANCED ANALYSIS COMPLETE!\n============================================================\nFinal model performance:\n  Cross-validation balanced accuracy: 0.862 Â± 0.054\n  Test set balanced accuracy: 0.819\n  Test set ROC-AUC: 0.912\n  Features used: 50 of 122 original features\n============================================================\n"}],"execution_count":2},{"id":"adf55b3f-db15-42a3-a167-5659ee4e7e09","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}